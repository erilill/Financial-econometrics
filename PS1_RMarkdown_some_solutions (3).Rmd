---
title: "Report for PS 1"
author:
- Mark Becker, Erik Lillrank & Vilim Nedic
- Another Author
date: ""
output:
  pdf_document:
    keep_tex: yes
  df_print: kable
  html_document:
    df_print: paged
toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(FE)
library(psych)
data("DJ_w")
data("DJ_d")
```

#  Statistical Properties of Asset Returns

## A. Distributional properties of Dow Jones index returns

### 1. Plot the series of log returns and compute descriptive statistics. Which distributional properties do you find? Do you find differences between daily and weekly data?

```{r PLOT1, echo=F}
ggplot(DJ_d, aes(y=r_Dow_Jones,x=1:nrow(DJ_d))) + geom_line() +
  labs(x='time horizon',y='daily log return')

ggplot(DJ_w, aes(y=r_close,x=1:nrow(DJ_w))) + geom_line() +
  labs(x='time horizon',y='weekly log return')

describe(DJ_d$r_Dow_Jones)
describe(DJ_w$r_close)

```
Both series have means of zero. Daily returns has standard deviation 0.01 and weekly returns 0.03. Daily returns has a skewness of -0.96 and kurtosis of 36.6.Weekly returns has a skewness of  -1.09 and kurtosis is 15.06. Since a standard normal distribution has a standard deviation of 1, skewness of 0 and kurtosis of 3, this is strong evidence that the returns are not normally distributed. We can further investigate which distribution seems most likely by producing QQ plots.

### 2. Evaluate the empirical distributions of the index log returns using quantile-quantile plots (QQ-plots). Test the empirical distribution against

#### a) a normal distribution (with same mean and variance)

```{r ndist}
ggplot()


```

#### b) alternative tn-distributions with n degrees of freedom.

 
```{r}
df = 3
tdistd = ggplot(DJ_d, aes(sample=r_Dow_Jones/sd(r_Dow_Jones)*sqrt(df/(df-2))))
tdistd + geom_qq(distribution=stats::qt, dparams=list(df=df)) + geom_abline(aes(intercept=0,slope=1),color="red") + 
  labs(y = "Daily returns")
qqplot(rt(length(DJ_d$r_Dow_Jones),df=3),DJ_d$r_Dow_Jones)

tdistw = ggplot(DJ_w, aes(sample=r_close/sd(r_close)*sqrt(df/(df-2))))
tdistw + geom_qq(distribution=stats::qt, dparams=list(df=df)) + geom_abline(aes(intercept=0,slope=1),color="red") + 
  labs(y = "Weekly returns")
qqplot(rt(length(DJ_w$r_close),df=3),DJ_w$r_close)
```


```{r}
df = 3
tdistw = ggplot(DJ_w, aes(sample=r_close/sd(r_close)*sqrt(df/(df-2))))
tdistw + geom_qq(distribution=stats::qt, dparams=list(df=df)) + geom_abline(aes(intercept=0,slope=1),color="red") + 
  labs(y = "Weekly returns")
qqplot(rt(length(DJ_w$r_close),df=3),DJ_w$r_close)
```
A visual analysis of the QQ-plots show that both empirical distribution could follow a t-distribution with 3 degrees of freedom. 

### 3. Compute a $\chi^2$-goodness-of-fit test against...

The $\chi^2$ test statistic is

$$
\chi^2=\sum_{j=1}^k \frac{(N_j-Np_j)^2}{Np_j} \sim^a \chi^2_{k-s-1},
$$
where $k$ is the number of categories, $N_j$ is the number of observations in the $j$th category, $p_j$ is the estimated probability for an observation in category $j$ and $s$ is the number of parameters to be estimated.

```{r}
vdata = DJ_d$r_Dow_Jones
vdata = DJ_w$r_close
vdata = (vdata - mean(vdata))/sd(vdata)

k = 20
grids = 1:k/k
```

#### a) a normal distribution

$H_0:$ The true distribution is the standard normal distribution.
```{r}
vq = pnorm(vdata); hist(vq)
vn = NULL; for(val in grids) vn = c(vn,sum(vq <= val))
vn = c(vn[1],diff(vn))
test = sum((vn-length(vdata)/ik)**2/(length(vdata)/ik))
cat("test =",test," df =",ik-3," p-value =",1-pchisq(test,df=ik-3))
```

#### b) a $t_n$-distribution with n degrees of freedom
```{r}
df = 3
ndata = vdata*sqrt(df/(df-2))

vq = pt(ndata,df=5); hist(vq)
vn = NULL; for(val in grids) vn = c(vn,sum(vq <= val))
vn = c(vn[1],diff(vn))
test = sum((vn-length(vdata)/ik)**2/(length(vdata)/ik))
cat("test =",test," df =",ik-3," p-value =",1-pchisq(test,df=ik-3))
```

#### c) a mixture of normal distributions with mixture probability $\alpha$ and variance $\sigma_2^2$
```{r}
alpha = 0.1514736
sigma = 4.0013995
alpha = 0.33
sigma = 2.73
ndata = vdata*sqrt((1-alpha) + alpha*sigma**2)

vq = (1-alpha)*pnorm(ndata) + alpha*pnorm(ndata,sd=sigma); hist(vq)
vn = NULL; for(val in grids) vn = c(vn,sum(vq <= val))
vn = c(vn[1],diff(vn))
test = sum((vn-length(vdata)/ik)**2/(length(vdata)/ik))
cat("test =",test," df =",ik-3," p-value =",1-pchisq(test,df=ik-3))

func <- function(vx){
  alpha = vx[1]
  sigma = vx[2]
  ndata = vdata*sqrt((1-alpha) + alpha*sigma**2)
  
  vq = (1-alpha)*pnorm(ndata) + alpha*pnorm(ndata,sd=sigma)
  vn = NULL; for(val in grids) vn = c(vn,sum(vq <= val))
  vn = c(vn[1],diff(vn))
  return(sum((vn-length(vdata)/ik)**2/(length(vdata)/ik)))
}

func(c(0.15,4))

optim(par=c(0.1,4),fn=func,method="BFGS")
```


## B. Dynamical properties of financial return series

```{r setupb, include=F}
data = index_d
```

### 1. Generate log returns. Compute the empirical autocorrelations and partial autocorrelations. Do you find evidence for significant autocorrelations in the individual index return series?

```{r}
lret = apply(log(data),2,diff)
summary(lret)
```
Above we generate the log returns, `lret`. Here we also see some summary statistics. From the summary, it is evident that mean and median for all series of the log returns are close to zero. Looking at the minimum and maximum values it seems that there could be skewness in some of the series. Below the log returns are plotted:

```{r}
matplot(lret,type='l',ylab='log returns',xlab='time horizon')
```
Here the plot shows low volatility with smaller spikes for most time periods. For the time period slightly below 500 we see a larger spike indicating stronger volatility during this period, possibly due to some extreme market event. The log returns are centered around zero over time, suggesting that there is no significant trend.

```{r}
sum(is.na(lret[,'FRCAC40']))
```
We see that we have missing values in the series `FRCAC40`, 393 missing values. Because there is missing values we can not calculate the autocorrelations without first handling these. The simplest way is to omit the missing values, however it is important to note that since there are quite many missing values this could lead to biased estimates or loss of power in the analysis. We proceed by performing listwise deletion. Assuming that we are not supposed to calculate cross-correlations, we proceed as follows:

```{r}
lret_clean <- lret[complete.cases(lret),]
par(mfrow=c(2,4))
for (i in 1:ncol(lret_clean)) {
  acf(lret_clean[, i], main = paste("ACF for series", i))
}
```

### 2. Compute the Ljung-Box test with respect to 10, 50 and 100 lags. By using the 0.01, 0.05 and 0.1 quantile of the $\chi^2$-distribution with suitable degrees of freedom, interpret your results.

```{r}
LB <- function(vx,lag,ip){
  tmp = acf(vx,lag.max=lag,plot=F)$acf
  tmp = tmp[2:(lag+1)]**2
  test = sum(tmp/(length(vx)-1:lag))*length(vx)*(length(vx)+2)
  return(list(test=test, pval=1-pchisq(test,df=lag-ip)))
}

tmp = 6
LB(vx=lret[!is.na(lret[,tmp]),tmp],lag=100,ip=0)
```

### 3. Compute the (pairwise) cross-autocorrelations between the individual return series. Do you find evidence for lead-lag relationships?

### 4. Generate squared log returns. Analyze their dynamical properties. What do you find?
