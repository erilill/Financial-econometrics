---
title: "Report for PS3"
author:
- Mark Becker, Erik Lillrank & Vilim Nedic
date: ''
output:
  pdf_document:
    keep_tex: true
  df_print: kable
  html_document:
    df_print: paged
  word_document: default
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
  - \usepackage{multirow}
  - \usepackage{caption}
  - \usepackage{subcaption}
  - \usepackage{adjustbox}
  - \usepackage{hyperref}
toc: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(FE)
library(knitr)
library(patchwork)
library(kableExtra)
library(dplyr)
library(psych)
library(car)
data("portfolio_m")
```

# A Size and book-to-market effects
Use the data set `portfolio_m` consisting of returns of U.S. stock portfolios built on size and book-to-market ratio according to Fama and French (1993, 1996). In the following you have to test the validity of the CAPM based on these portfolios.

## 1. Analyze the descriptive statistics of the returns of the different portfolios. Do you find systematic differences in dependence of size and the book-to-market ratio?

```{r descriptive, echo=F}
descriptive_stats <- describe(portfolio_m[,5:24])[,c("mean", "sd", "skew", "kurtosis", "min", "max")]
kable(descriptive_stats, digits = 3)
```
What we see in the table above is that the smaller firms (ME1-ME3) have higher average returns (larger means) and volatility (larger standard deviations) than the larger firms (e.g. ME10). Looking at the book-to-market effect, the higher book-to-market (e.g. MEBE10) portfolios exhibit higher average returns (larger means) and volatility (larger standard deviations) compared to the lower book-to-market (MEBE1) portfolios. For the ME portfolios we see positive skewness that is decreasing with the size, i.e. smaller firms are more positively skewed, indicating occasional extreme positive returns, and this seems to decrease with size. For MEBE portfolios, they seem to be more symmetric for the smaller book-to-market portfolios with some slightly negative skewness. But then from the 4th decile and up, instead it seems that skewness increases (positive) with larger book-to-market size. The smaller firms and higher book-to-market portfolios have high kurtosis, suggesting heavy-tailed return distributions. Looking at the minimum and maximum values we also see that for the smaller firms and higher book-to-market portfolios there are extreme returns. From the descriptive statistics we see evidence of both the size effect and the value effect.


## 2. For all individual size and book-to-market portfolios as well as the market portfolio(s), compute the corresponding excess returns. Then, estimate the CAPM for selected portfolios and answer the following questions:

We start by computing the excess returns, which are given by:

$$
Z_{it} = R_{it}-R_f \quad and \quad Z_{mt}=R_{mt}-R_f
$$

```{r}
excess_returns <- portfolio_m[,c(3,5:24)]-portfolio_m$Tbill
```
The next step is to fit the following regression equation:

$$
Z_{it}=\alpha_i + \beta_i Z_{mt} + \epsilon_{it}
$$

Implementing in `R` using a simple `for`-loop:

```{r}
results <- data.frame(
  Portfolio = character(),
  Alpha = numeric(),
  Beta = numeric(),
  R2 = numeric(),
  StdErrAlpha = numeric(),
  StdErrBeta = numeric(),
  PValueAlpha = numeric(),
  PValueBeta = numeric(),
  stringsAsFactors = FALSE
)

portfolios <- colnames(excess_returns)[2:21]
for (i in portfolios){
  ER <- excess_returns[[i]]
  capm_model <- lm(ER ~ excess_returns$Market)
  
  alpha <- coef(capm_model)["(Intercept)"]
  beta <- coef(capm_model)["excess_returns$Market"]
  r_squared <- summary(capm_model)$r.squared
  std_err_alpha <- coef(summary(capm_model))["(Intercept)", "Std. Error"]
  std_err_beta <- coef(summary(capm_model))["excess_returns$Market", "Std. Error"]
  p_value_alpha <- coef(summary(capm_model))["(Intercept)", "Pr(>|t|)"]
  p_value_beta <- coef(summary(capm_model))["excess_returns$Market", "Pr(>|t|)"]
  
  results <- rbind(
    results,
    data.frame(
      Portfolio = i,
      Alpha = alpha,
      Beta = beta,
      R2 = r_squared,
      StdErrAlpha = std_err_alpha,
      StdErrBeta = std_err_beta,
      PValueAlpha = p_value_alpha,
      PValueBeta = p_value_beta
    )
  )
}

rownames(results) <- NULL
kable(results, digits = 3, caption = "Estimated CAPM for the portfolios", label = "tab:capm1")
```


### (a) Test the validity of the CAPM for the individual size and book-to-market portfolios. Can you confirm the CAPM relationship across the cross-section of size and book-to-market portfolios?

What we will be inspecting in order to answer this question is $\alpha$ and the corresponding p-value. In CAPM, $\alpha$ represents the excess return not explained by the market. For CAPM to hold, $\alpha$ should be statistically insignificant i.e. close to zero/we can not reject that it is 0, and $\beta$ should capture the cross-sectional variation of expected excess returns.

In table 2 we see that $\alpha$ is only statistically significant at 10\% for MEBE5 and MEBE8, with only MEBE8 being significant at 5\%. We see that we can not reject $\alpha$ being zero for all other portfolios, however we do see that the estimates although insignificant are higher for smaller portfolios and for higher book-to-market portfolios. Based on these results it seems that CAPM is valid for most of the portfolios, however it holds better for portfolios of larger firms and lower book-to-market portfolios. 

### (b) Is there a systematic relation between the estimated market beta and size as well as the book-to-market ratio? Interpret your findings.

Looking at the $\beta$'s in table 2, we see that the portfolios of smaller firms tend to have higher $\beta$'s while the portfolios of larger firms have lower $\beta$'s. This indicates that the returns of smaller firms are more volatile than the returns of larger firms. Also ME10 has a $\beta<1$, which indicates that the largest firms have returns less volatile than the market. The rest of the ME have $\beta >1$, meaning they have returns more volatile than the market. We also see that $\beta$'s are higher for highest book-to-market portfolios compared to lower book-to-market portfolios. This indicates that the higher book-to-market portfolios have more volatile returns than the lower book-to-market portfolios. For the ME portfolios some have $\beta<1$ and some $\beta>1$ so some are more volatile than the market and some are less volatile.

### (c) Is there a systematic relation between the \(R^2\) and market capitalization as well as book-to-market ratio? What does this mean?

Looking at the $R^2$'s, we see that it is lower for the lower market capitalization portfolios compared to the higher market capitalization portfolios, This suggests that CAPM captures most of the variation in excess return for the higher market capitalization portfolios while the explanatory power is weaker for the smaller portfolios. 

Looking at the relation between $R^2$ and the book-to-market ratio, we see that the explanatory power is stronger for the portfolios of lower book-to-market ratio compared to those with higher.

In conclusion, these results suggests that CAPM performs well for larger stocks and for lower book-to-market portfolios, but for smaller portfolios and higher book-to-market portfolios, the $\alpha$'s and lower $R^2$ suggests that other factors than market risk could be driving returns.

## 3. Estimate the CAPM jointly for the complete set of size portfolios, book-to-market portfolios as well as portfolios built on the intersections of size and book-to-market deciles. Test for joint significance of the intercept terms using the F-test.

In this question we will use the `FamaMacbeth0()` function which was given in the assignment in order to estimate the joint CAPM and test for joint significance of the intercept terms using the F-test. So we test the following for the vector of intercept terms

$$
\begin{aligned}
H_0:\alpha &=0\\
H_a:\alpha &\neq0
\end{aligned}
$$
on a usual 5% significance level. The test used is the F-test proposed by Gibbons/Ross/Shanken 1989:

$$
J_1 = \frac{T-N-1}{N}\left[1+\frac{\hat{\mu}_m^2}{\hat{\sigma}^2_m} \right]^{-1} \hat{\alpha}^{\prime}\hat{\Sigma}^{-1}\hat{\alpha}\sim F_{N,T-N-1}
$$
where
$$
x = \sqrt{T}\left[1+\frac{\hat{\mu}_m^2}{\hat{\sigma}^2_m}\right]^{-1}\hat{\alpha},\;\; A=T\hat{\Sigma}, \;\; m=N, \;\; n=T-2
$$

```{r, echo=F}
FamaMacbeth0 <- function(mZ, vZm)
{
  iT = nrow(mZ)
  iN = ncol(mZ)
  
  # First Pass
  mX = cbind(1,vZm)
  pars = chol2inv(chol(crossprod(mX)))%*%crossprod(mX,mZ)
  alpha = c(pars[1,])
  # estimated betas
  beta = c(pars[2,])
  # sample mean of each excess return
  mu = apply(mZ,2,mean)
  # sample mean of the market excess return
  mum = mean(vZm)
  # variance of the market excess return
  sigm2 = c(crossprod(vZm-mum))/iT
  # residules
  me = mZ-mX%*%pars
  # covariance matrix of the residules
  Sigma = crossprod(me)/iT
  
  # do the test on pp.24 & 25 in slides for lecture 4
  tmp = c(t(alpha)%*%chol2inv(chol(Sigma))%*%alpha)/(1+mum^2/sigm2)
  
  # Gibbons/Ross/Shanken (1989)
  J1 = tmp*(iT-iN-1)/iN
  jpval = 1-pf(J1,df1=iN,df2=iT-iN-1)
  
  # Wald
  W = tmp*iT
  wpval = 1-pchisq(W,df=iN)
  
  # modified LR, Jobson/Korkie (1982)
  mX = matrix(vZm,iT,1)
  pars = chol2inv(chol(crossprod(mX)))%*%crossprod(mX,mZ)
  me = mZ-mX%*%pars
  # covariance matrix of the residules
  SigmaR = crossprod(me)/iT
  LR = (sum(log(eigen(SigmaR)$values))-sum(log(eigen(Sigma)$values)))*(iT-iN/2-2)
  lrpval = 1-pchisq(LR,df=iN)
  
  
  # Second Pass
  mX = cbind(1,beta)
  xxinv = chol2inv(chol(crossprod(mX)))
  xxinvx = tcrossprod(xxinv,mX)
  gamma = NULL; gamsd = NULL
  for(iter in 1:iT){
    vy = mZ[iter,]
    tmp = xxinvx%*%vy
    # gamma
    gamma = rbind(gamma, c(tmp))
    s2 = c(crossprod(vy - mX%*%tmp))/iN
    # gammas' standard error
    gamsd = rbind(gamsd, sqrt(diag(s2 * xxinv)))
  }
  
  # gamma0 and market risk premia
  gamma0 = c(gamma[,1]); g0sd = c(gamsd[,1])
  mrprem = c(gamma[,2]); prsd = c(gamsd[,2])
  
  # w tests on pp.30 in slides for lecture 4
  # should be compared with student t with T-1 degrees of freedom
  # or with standard normal if T is large
  wgamma0 = mean(gamma0)/sqrt(sum((gamma0-mean(gamma0))**2)/iT/(iT-1))
  wgamma1 = mean(mrprem)/sqrt(sum((mrprem-mean(mrprem))**2)/iT/(iT-1))
  
  return(list(alpha=alpha,beta=beta,J1=c(J1,jpval),W=c(W,wpval),mLR=c(LR,lrpval),
              gamma0=gamma0,g0sd=g0sd,mrprem=mrprem,prsd=prsd,wgamma0=wgamma0,wgamma1=wgamma1))
}

mR = as.matrix(portfolio_m[,5:124])
Rf = as.matrix(portfolio_m[,'Tbill'])
Rm = as.matrix(portfolio_m[,'Market'])
mZ = sweep(mR,1,Rf)

vZm = Rm - Rf

ret = FamaMacbeth0(mZ=mZ, vZm=vZm)
J1_stat <- ret$J1[1]
p_value <- ret$J1[2]

J1_results <- data.frame(
  Test = c("F-test Statistic (J1)", "P-value"),
  Value = c(round(ret$J1[1], 4), round(ret$J1[2], 4))
)
kable(J1_results, caption = "F-test Results for Joint Significance of Intercepts", label="tab:Ftest")
```
In table 3 we see the results from the F-test. We see in the table that the p-value is very close to zero, so we can see that we reject the null of $\alpha=0$ on a 5% (also 1%) significance level. The interpretation is that we have strong evidence that at least 1 of the intercept terms $\alpha_i$ in the intercept vector $\alpha$ is significantly different from zero. So we can on the basis of this test conclude that CAPM does not seem to hold, when we estimate it jointly for all the portfolios.

## 4. Use the 100 portfolios built on the intersections of size and book-to-market deciles and divide the sample in appropriate sub-periods. Specify a CAPM which allows for period-specific betas and intercept terms. Estimate the model for these portfolios.

We chose to divide the sample into three even sub-periods. In order to include period-specific betas and intercept terms, we computed dummy variables for periods two and three. These dummy variables will act as our period specific intercepts, we did not include a dummy for the first period as this will cause multi-collinearity. The period specific intercepts are then given by:

$$
\begin{aligned}
\alpha_{Period\;1} &=\alpha \\
\alpha_{Period\;2} &=\alpha+\gamma_2 \\
\alpha_{Period\;3} &=\alpha +\gamma_3\\
\end{aligned}
$$
With $\gamma$ denoting the coefficients for the dummy variables $D_2$ and $D_3$. 

In order to include period-specific betas, we include interaction terms between the period dummies and the market excess:

$$
\delta_4(D_2*Z_{mt}) \quad and \quad \delta_5(D_3*Z_{mt})
$$
Such that the CAPM model is:

$$
Z_{t}=\alpha_t+\beta_1Z_{mt}+\gamma_2+\gamma_3+\delta_4(D_2*Z_{mt}) + \delta_5(D_3*Z_{mt})+\epsilon_{t}
$$

```{r}
# Divide data into sub-periods, 314 time-points in each
subsample1 <- 1:314
subsample2 <- 315:628
subsample3 <- 629:942

#Create dummies
portfolio_m$Period2 <- 0
portfolio_m$Period3 <- 0
portfolio_m[subsample2,]$Period2 <- portfolio_m[subsample2,]$Period2 + 1
portfolio_m[subsample3,]$Period3 <- portfolio_m[subsample3,]$Period3 + 1

excess_returns <- portfolio_m[,c(3,25:124)]-portfolio_m$Tbill



results <- data.frame(
  Portfolio = character(),
  Alpha = numeric(),
  Beta = numeric(),
  Period2Coef = numeric(),
  Period3Coef = numeric(),
  InteractionPeriod2Market = numeric(),
  InteractionPeriod3Market = numeric(),
  R2 = numeric(),
  adj_R2 = numeric(),
  StdErrAlpha = numeric(),
  StdErrBeta = numeric(),
  PValueAlpha = numeric(),
  PValueBeta = numeric(),
  PValuePeriod2 = numeric(),
  PValuePeriod3 = numeric(),
  PValueInteractionPeriod2Market = numeric(),
  PValueInteractionPeriod3Market = numeric(),
  stringsAsFactors = FALSE
)

# Initialize variables for global TSS and RSS
global_tss <- 0
global_rss <- 0

portfolios <- colnames(excess_returns)[2:101]
# Loop through each portfolio
portfolios <- colnames(excess_returns)[2:101]
for (i in portfolios) {
  ER <- excess_returns[[i]]
  
  # Fit CAPM model with period-specific betas and intercepts (interaction terms)
  capm_model <- lm(ER ~ excess_returns$Market + portfolio_m$Period2 + portfolio_m$Period3 + 
                    portfolio_m$Period2 * excess_returns$Market + portfolio_m$Period3 * excess_returns$Market)
  
  # Extract coefficients, p-values, and statistics
  alpha <- coef(capm_model)["(Intercept)"]
  beta <- coef(capm_model)["excess_returns$Market"]
  period2_coef <- coef(capm_model)["portfolio_m$Period2"]
  period3_coef <- coef(capm_model)["portfolio_m$Period3"]
  interaction_period2_market <- coef(capm_model)["excess_returns$Market:portfolio_m$Period2"]
  interaction_period3_market <- coef(capm_model)["excess_returns$Market:portfolio_m$Period3"]
  
  r_squared <- summary(capm_model)$r.squared
  adj_r_squared <- summary(capm_model)$adj.r.squared
  std_err_alpha <- coef(summary(capm_model))["(Intercept)", "Std. Error"]
  std_err_beta <- coef(summary(capm_model))["excess_returns$Market", "Std. Error"]
  
  # Extract p-values
  p_value_alpha <- coef(summary(capm_model))["(Intercept)", "Pr(>|t|)"]
  p_value_beta <- coef(summary(capm_model))["excess_returns$Market", "Pr(>|t|)"]
  p_value_period2 <- coef(summary(capm_model))["portfolio_m$Period2", "Pr(>|t|)"]
  p_value_period3 <- coef(summary(capm_model))["portfolio_m$Period3", "Pr(>|t|)"]
  p_value_interaction_period2_market <- coef(summary(capm_model))["excess_returns$Market:portfolio_m$Period2", "Pr(>|t|)"]
  p_value_interaction_period3_market <- coef(summary(capm_model))["excess_returns$Market:portfolio_m$Period3", "Pr(>|t|)"]
  
  # Update global RSS (Residual Sum of Squares)
  global_rss <- global_rss + sum(capm_model$residuals^2)
  
  # Update global TSS (Total Sum of Squares)
  global_tss <- global_tss + sum((ER - mean(ER))^2)
  
  # Store results in data frame
  results <- rbind(
    results,
    data.frame(
      Portfolio = i,
      Alpha = alpha,
      Beta = beta,
      Period2Coef = period2_coef,
      Period3Coef = period3_coef,
      InteractionPeriod2Market = interaction_period2_market,
      InteractionPeriod3Market = interaction_period3_market,
      R2 = r_squared,
      adj_R2 = adj_r_squared,
      StdErrAlpha = std_err_alpha,
      StdErrBeta = std_err_beta,
      PValueAlpha = p_value_alpha,
      PValueBeta = p_value_beta,
      PValuePeriod2 = p_value_period2,
      PValuePeriod3 = p_value_period3,
      PValueInteractionPeriod2Market = p_value_interaction_period2_market,
      PValueInteractionPeriod3Market = p_value_interaction_period3_market
    )
  )
}

R2 <- 1 - (global_rss / global_tss)
rownames(results) <- NULL
```



### (a) Do you find statistically significant evidence for time-varying market betas and intercept terms?

We can perform the Chow Test. We estimate the full sample CAPM as

$$
Z_{it}=\alpha + \beta Z_{mt} + \epsilon_{it}
$$
We can split up the data into two groups, i.e. the first half of the data and the second half like

$$
\begin{aligned}
Z_{it}=\alpha^{(1)} + \beta^{(1)} Z_{mt} + \epsilon_{it}\\
Z_{it}=\alpha^{(2)} + \beta^{(2)} Z_{mt} + \epsilon_{it}
\end{aligned}
$$
The null of the Chow test asserts that $\alpha^{(1)}=\alpha^{(2)},\beta^{(1)}=\beta^{(2)}$, under the assumption that $\epsilon_{it} \overset{\mathrm{iid}}{\sim} N(0,\sigma^2)$. Then we have the Chow test statistic

$$
\frac{(S_C-(S_1+S_2))/k}{(S_1+S_2)/(N_1+N_2-2k)} \sim F_{k,N_1+N_2-2k}
$$
where $S_C$ is the sum of squared residuals from the full data sample, $S_1$ be the sum of squared residuals from the first group, $S_2$ be the sum of squared residuals from the second group, $N_1$ and $N_2$ are the number of observations in each group and $k$ is the total number of parameters estimated.

```{r}
# Chow test

# chow test function
my.chow.test <- function(y1,x1,y2,x2){
  
  full_sample_fit <- lm(c(y1,y2)~c(x1,x2))
  
  S_C <- sum(full_sample_fit$residuals^2)
  k <- length(full_sample_fit$coefficients)
  
  N_1 <- length(y1)
  N_2 <- length(y2)
  
  group_1_fit <- lm(y1~x1)
  group_2_fit <- lm(y2~x2)
  
  S_1 <- sum(group_1_fit$residuals^2)
  S_2 <- sum(group_2_fit$residuals^2)
  
  Chow_test_stat <- ((S_C-(S_1+S_2))/k)/((S_1+S_2)/(N_1+N_2-2*k))
  
  pval = 1-pf(Chow_test_stat,df1=k,df2=N_1+N_2-2*k)
  
  return(c(Fstat=Chow_test_stat, df1=k,df2=N_1+N_2-2*k, pvalue=pval))
}

#divide the data into 2 groups, first half and second half
t1 <- 1:471
t2 <- 472:942

ER_M <- as.matrix(portfolio_m[,3]-portfolio_m$Tbill) #full sample market excess returns
x1 <- ER_M[t1] #period 1
x2 <- ER_M[t2] #period 2

# 25:124 all Rx(x)y(y) portfolios
pvals <- numeric(length(25:124))

for (i in 25:124){
  ER <- as.matrix(portfolio_m[,i]-portfolio_m$Tbill) #portfolio excess returns
  y1 <- ER[t1] #period 1
  y2 <- ER[t2] #period 2
  pvals[i-24] <- my.chow.test(y1,x1,y2,x2)[4] #p-value
}

#plot the p-values
library(ggplot2)
pvalsdf <- data.frame(pvals)
plot <- ggplot(pvalsdf, aes(x=pvals)) + 
  geom_histogram()

plot + geom_vline(aes(xintercept=0.05),
            color="blue", linetype="dashed", linewidth=1)

length(pvals)
sum(pvals<0.05)
```

For 80 out of the 100 portfolios, we reject the null hypothesis that $\alpha^{(1)}=\alpha^{(2)},\beta^{(1)}=\beta^{(2)}$ at a 5% level, indicating that the vast majority of the portfolios seems to have time-varying market betas and intercept terms.


### (b) Analyze wether the inclusion of period-specific effects does increase the model's goodnes-of-fit.

In order to answer this question, we will look at the coefficient of determination ($R^2$) of the extended CAPM and the CAPM without period-specific effects. This is calculated as:

$$
R^2 = 1-\frac{SS_{res}}{SS_{tot}}
$$
Where SS denotes the sum of squares of the residuals and the total sum of squares. As including more variables always increase $R^2$, we will also investigate the adjusted $R^2$ which penalizes based on number of coefficients.


```{r, include=F}
results2 <- data.frame(
  Portfolio = character(),
  Alpha = numeric(),
  Beta = numeric(),
  R2 = numeric(),
  adj_R2 = numeric(),
  StdErrAlpha = numeric(),
  StdErrBeta = numeric(),
  PValueAlpha = numeric(),
  PValueBeta = numeric(),
  stringsAsFactors = FALSE
)

# Initialize variables for global TSS and RSS
global_tss <- 0
global_rss <- 0

for (i in portfolios) {
  ER <- excess_returns[[i]]
  
  # Fit CAPM model with period-specific betas and intercepts (interaction terms)
  capm_model <- lm(ER ~ excess_returns$Market)
  
  # Extract coefficients, p-values, and statistics
  alpha <- coef(capm_model)["(Intercept)"]
  beta <- coef(capm_model)["excess_returns$Market"]
  
  r_squared <- summary(capm_model)$r.squared
  adj_r_squared <- summary(capm_model)$adj.r.squared
  std_err_alpha <- coef(summary(capm_model))["(Intercept)", "Std. Error"]
  std_err_beta <- coef(summary(capm_model))["excess_returns$Market", "Std. Error"]
  
  # Extract p-values
  p_value_alpha <- coef(summary(capm_model))["(Intercept)", "Pr(>|t|)"]
  p_value_beta <- coef(summary(capm_model))["excess_returns$Market", "Pr(>|t|)"]
  
  # Update global RSS (Residual Sum of Squares)
  global_rss <- global_rss + sum(capm_model$residuals^2)
  
  # Update global TSS (Total Sum of Squares)
  global_tss <- global_tss + sum((ER - mean(ER))^2)
  
  # Store results in data frame
  results2 <- rbind(
    results2,
    data.frame(
      Portfolio = i,
      Alpha = alpha,
      Beta = beta,
      R2 = r_squared,
      adj_R2 = adj_r_squared,
      StdErrAlpha = std_err_alpha,
      StdErrBeta = std_err_beta,
      PValueAlpha = p_value_alpha,
      PValueBeta = p_value_beta
    )
  )
}

rownames(results2) <- NULL
R2_2 <- 1 - (global_rss / global_tss)
```
We will start by comparing the $R^2$ for each individual portfolio, comparing the model with time specific $\alpha$'s and $\beta$'s to the CAPM with no period specific terms:

```{r, echo=F}
num_higher_r2 <- sum(results$R2 > results2$R2)
num_higher_adj_r2 <- sum(results$adj_R2 > results2$adj_R2)

cat("Comparison of models with and without period-specific terms:\n")
cat("- Number of portfolios where R² is higher with period-specific terms:", num_higher_r2, "\n")
cat("- Number of portfolios where adjusted R² is higher with period-specific terms:", num_higher_adj_r2, "\n")
```
Looking at the CAPM where we include period-specific effects, we see that all individual $R^2$ are larger compared to the original CAPM. Looking at the adjusted $R^2$, we see that 95/100 $R^2_{adj.}$ are larger. However, this is not necessarily an indication that goodness-of-fit drastically improves. Not included here for brevity, but looking at the difference between these individual $R^2$, we see that the differences are very small between the two CAPM models. 

In the table below, you see the global $R^2$ for the two models.

```{r, echo=F}
r22 <- rbind(R2_2, R2)
rownames(r22) <- c("CAPM without period-specific terms", "CAPM with period-specific terms")
kable(r22, col.names = "R2")
```
In this table we see that the difference in $R^2$ between the two models is very small. Based on this we do not believe that the inclusion of period-specific effects drastically increases the model's goodness-of-fit.

### (c) Do you find for particular size and book-to-market portfolios stronger time variations in market betas than for other?

```{r, echo=F}
beta_period1 <- results$Beta
beta_period2 <- beta_period1 + results$InteractionPeriod2Market
beta_period3 <- beta_period1 + results$InteractionPeriod3Market
betas <- cbind(beta_period1, beta_period2, beta_period3)
rownames(betas) <- colnames(excess_returns)[2:101]

# Calculate variance of betas across periods
beta_variation <- apply(betas, 1, var)

# Extract size and book-to-market deciles from portfolio names
portfolio_names <- colnames(excess_returns)[2:101]

# Function to extract size and book-to-market deciles
extract_deciles <- function(name) {
  # Extract size decile
  if (substr(name, 2, 3) == "10") {
    size_decile <- 10  # For size 10 decile
  } else {
    size_decile <- as.numeric(substr(name, 2, 2))  # Otherwise, take the second character
  }
  
  # Extract book-to-market decile
  if (substr(name, 4, 5) == "10" || substr(name, 3, 4) == "10") {
    book_to_market_decile <- 10  # For book-to-market 10 decile
  } else {
      if (is.na(as.numeric(substr(name, 4, 4)))){
        book_to_market_decile <- as.numeric(substr(name, 3, 3))
      } else{
    book_to_market_decile <- as.numeric(substr(name, 4, 4))
        }
    }
                                      
  return(c(size_decile, book_to_market_decile))
}

# Apply function to all portfolio names
deciles <- t(sapply(portfolio_names, extract_deciles))
size_decile <- deciles[, 1]
book_to_market_decile <- deciles[, 2]

# Combine beta variation with size and book-to-market deciles
beta_variation_df <- data.frame(
  Portfolio = portfolio_names,
  Size = as.factor(size_decile),
  BookToMarket = as.factor(book_to_market_decile),
  BetaVariation = beta_variation
)

# Alternatively, create a heatmap
ggplot(beta_variation_df, aes(x = Size, y = BookToMarket, fill = BetaVariation)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "darkblue") +
  labs(title = "Heatmap of Beta Variation by Size and Book-to-Market",
       x = "Size Decile",
       y = "Book-to-Market Decile",
       fill = "Beta Variation") +
  theme_minimal()
```
Above we have plotted the variation in betas between time periods against the Size decile and book-to-market ratios. The pattern we see is that the portfolios consisting of larger size firms seem to have less variation in betas between the time periods. Portfolios with lower book-to-market ratios also have smaller variance in the betas between time periods. 

Based on this plot, it seems that high book-to-market portfolios are most volatile over time as the variation in beta is high for almost all portfolios with high book-to-market. There also seem to be a relationship between size and time variation, however this relationship does not seem to be as strong based on the above plot. In contrast, larger portfolios with low book-to-market is least volatile.

# B. Cross-sectional regressions
Use the data set `portfolio_m` analyzed in the previous section. In the following you have to analyze the cross-sectional implications of the CAPM

## 1. Write R code to implement the First Pass regression which computes the cross-section of market betas, and save them together with the period-specific excess returns. Apply the code to compute the betas for the 100 size-book-to-market portfolios. Using the results to analyze the following issues:

```{r, echo=T}
FirstPass <- function(mZ, vZm){
  iT = nrow(mZ)
  iN = ncol(mZ)
  
  # First Pass
  mX = cbind(1,vZm)
  pars = chol2inv(chol(crossprod(mX)))%*%crossprod(mX,mZ)
  alpha = c(pars[1,])
  # estimated betas
  beta = c(pars[2,])
  # sample mean of each excess return
  mu = apply(mZ,2,mean)
  # sample mean of the market excess return
  mum = mean(vZm)
  # variance of the market excess return
  sigm2 = c(crossprod(vZm-mum))/iT
  # residuals
  me = mZ-mX%*%pars
  # covariance matrix of the residuals
  Sigma = crossprod(me)/iT
  #predicted values
  mZ_hat <- mX%*%pars
  #residuals
  mResiduals <- mZ - mZ_hat
  #vector to store R^2 values for each portfolio
  R2 = numeric(iN)
  
  for (j in 1:iN) {
    # Residual Sum of Squares for portfolio j
    RSS_j = sum(mResiduals[, j]^2)
    # Total Sum of Squares for portfolio j
    TSS_j = sum((mZ[, j] - mean(mZ[, j]))^2)
    # R-squared for portfolio j
    R2[j] = 1 - RSS_j / TSS_j
  }
  return(list(alpha=alpha,beta=beta,R2=R2,mu=mu,mum=mum))
}

mR = as.matrix(portfolio_m[,25:124])
Rf = as.matrix(portfolio_m[,'Tbill'])
Rm = as.matrix(portfolio_m[,'Market'])
mZ = sweep(mR,1,Rf)
vZm = Rm - Rf

fpreg <- FirstPass(mZ, vZm)
```

### (a) Evaluate the cross-sectional distribution of the estimated betas. Test whether the average betas are significantly different from one. Interpret your findings.

First we evaluate the cross-sectional distribution of the estimated betas.

```{r}
descriptive_stats <- describe(fpreg$beta)[,c("mean","median", "sd", "skew", "kurtosis", "min", "max")]
rownames(descriptive_stats) <- "beta"
kable(descriptive_stats, digits = 3)
```

We can see that the mean is 1.171 and median is also 1.171 which means that these portfolios points towards slightly higher systematic risk compared to the market where the expectation of beta would be 1. 
The standard deviation of 0.18 so overall a quite low spread of the betas across the portfolios. The distribution seems to be slightly negatively skewed capturing some portfolios who exhibit low betas, i.e. lower risk compared to market, but that most portfolios have high betas. Furthermore, the distribution is quite thin tailed considering a kurtosis of 0.422. The difference of the absolute values of the min and max show the asymmetry/skewness.

Now lets plot the histogram of the betas and plot the QQ-plot to see these findings visually.
```{r}
hist(fpreg$beta)
lines(density(fpreg$beta), col = "blue", lwd = 2)
abline(v = descriptive_stats$mean, col = "red", lwd = 2, lty = 2)
qqnorm(fpreg$beta)
qqline(fpreg$beta, col = "red")
```
The blue line is the density line for the betas and the red dashed vertical line is the mean. The QQ-plot shows the data compared to a theoretical normal distribution and we can see that the betas are not quite normally distributed. The QQ-plot shows that the tails of the empircal distribution is not quite as the theoretical normal. The bulk of the data looks to approximately follow a normal distribution quite good but this still points towards that the data is not quite normally distributed. Although since we use OLS, under certain assumptions, in large samples, OLS estimator of beta is normal, so if we would have a larger sample, perhaps we would see it to be more normally distributed.

Now to test whether the average beta is significantly different from one. Let us divide the data in three equally large periods again, first, middle and last part of the data, and to the test for each period.

```{r}
# Divide data into sub-periods, 314 time-points in each
subsample1 <- 1:314
subsample2 <- 315:628
subsample3 <- 629:942
subsamples <- list(subsample1,subsample2,subsample3)
```

We test on a 5% significance level
$$
\begin{aligned}
H_0:\mu_{\hat{\beta}}=1\\
H_a:\mu_{\hat{\beta}}\neq1
\end{aligned}
$$
So we can use the test statistic

$$
T=\frac{\hat{\mu}_{\hat{\beta}}-1}{\hat{\sigma}_{\hat{\beta}}/\sqrt{n}} \sim t_{n-1}
$$
Note that we do this test under the assumption that the $\hat{\beta}$'s are i.i.d. which may not be very realistic. Lets implement it in code and do the test for each period

```{r}
means <- numeric(length(subsamples))
tstats <- numeric(length(subsamples))
pvals <- numeric(length(subsamples))
tcheck <- list()

betas_list <- list()

for (i in 1:length(subsamples)){
  mR = as.matrix(portfolio_m[subsamples[[i]],25:124])
  Rf = as.matrix(portfolio_m[subsamples[[i]],'Tbill'])
  Rm = as.matrix(portfolio_m[subsamples[[i]],'Market'])
  mZ = sweep(mR,1,Rf)
  vZm = Rm - Rf

  tmp = FirstPass(mZ, vZm)
  betas <- tmp$beta
  betas_list[[i]] <- betas
  means[i] <- mean(betas)

  Tstat <- (mean(betas)-1)/(sd(betas)/sqrt(length(betas)))
  pval <- 2*pt(abs(Tstat), df=length(betas)-1,lower.tail=FALSE)
  
  tstats[i] <- Tstat
  pvals[i] <- pval
  tcheck[[i]] <- t.test(betas,mu=1)
}

data <- data.frame(
  Metric = c("sample mean", "t-stat", "p-value"),
  Period_1 = c(round(means[1],4), round(tstats[1],4), round(pvals[1],4)),
  Period_2 = c(round(means[2],4), round(tstats[2],4), round(pvals[2],4)),
  Period_3 = c(round(means[3],4), round(tstats[3],4), round(pvals[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "period specific t-test for average beta =1"
)
```

We can see that for period 1 and period 2, we strongly reject the null, i.e. the average beta in both periods is significantly different from one. Although in period 3, the p-value is really high at 0.96, so for period 3 we definitely do not reject the null, so we accept the alternative that the average beta in period 3 is 1.

### (b) Evaluate the cross-sectional distribution of the computed (time series) \(R^2\)'s. What can you learn from this analysis?

```{r}
descriptive_stats <- describe(fpreg$R2)[,c("mean", "median", "sd", "skew", "kurtosis", "min", "max")]
rownames(descriptive_stats) <- "R^2"
kable(descriptive_stats, digits = 3)
```

We can see that is quite heavily left skewed with skewnewss of -0.817. First of all the mean is slightly lower than the median indicating that there are some $R^2$ on the lower end pulling the mean down and therefore pointing towards a left skewed data. The negative kurtosis indicates on a platykurtic distribution where most of the values are around the mean. The standard deviation is quite low but relative to this data it describes a moderate variability for $R^2$. The lowest value is 0.186 and the highest value is 0.873 which shows a fairly high spread and implies that some of the models have low explanatory power but most of them have a high explanatory power since the majority of the data is around the mean and in the range between 0.6 and 0.8. 


```{r}
hist(fpreg$R2)
lines(density(fpreg$R2), col = "blue", lwd = 2)
abline(v = descriptive_stats$mean, col = "red", lwd = 2, lty = 2)
```
We clearly see the left skewness, i.e. a lot of higher $R^2$ happens to the right, so in essence in most cases the $R^2$ is high/, i.e. the market excess returns explains quite a lot of the variation in the portfolio excess returns. These findings indicate that for most portfolios, the CAPM holds quite well/is a decent model of the data. The negative skewness indicates that some models have poor explanatory power and this can be due to idiosyncratic or sector-specific behavior.


### (c) Evaluate the relationship between average excess returns and market betas. What would you expect from economic theory and what do you find?

Now the economic theory says that the CAPM implies

$$
E[Z_{it}]=\beta_iE[Z_{mt}]
$$
Now we want to verify to what extent this is correct. We do not have the expectations, so a (not so mathematically rigorous) compromise is to use the averages, and see if it holds, i.e. does the following equation approximately hold?

$$
T^{-1}\sum_{t=1}^TZ_{it}=\beta_iT^{-1}\sum_{t=1}^TZ_{mt}
$$
Set up the equation in the code

```{r}
# sample mean of each excess return
mu <- fpreg$mu
# sample mean of the market excess return
mum <- fpreg$mum
# betas
beta <- fpreg$beta

lhs <- mu # left hand side of equation
rhs <- beta * mum # right hand side of equation
```

Now if we plot a scatterplot with the left hand side against the right hand side against the equation, if it holds perfectly, we should see that all points lie on a 45 degree line, i.e. the economic theory prediction (CAPM) is the 45 degree line. Lets try it

```{r}
library(ggplot2)

# Create a data frame for visualization
data <- data.frame(lhs = lhs, rhs = rhs)

# Scatter plot with a 45-degree reference line
ggplot(data, aes(x = rhs, y = lhs)) +
  geom_point(color = "blue", size = 2) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "CAPM Predictions (red line) vs. empirical reality (blue points)",
    x = "Beta * average Market Excess Return",
    y = "Average Portfolio Excess Return"
  ) +
  theme_minimal()
```
We can see that it seems to hold relatively well for some portfolios, but not for others. Some are really really close on the line, so for these portfolios the CAPM prediction from economic theory holds really well. But for other portfolios, CAPM does not hold very well.

## 2 Estimate the following cross-sectional model for individual periods t in Second Pass:

$$
Z_t = \gamma_{0t} \iota + \gamma_{1t}\hat{\beta}_m + \eta_t
$$

where $Z_t$ is an $N\times 1$ vector of excess asset returns for time period t, $\iota$ is an $N\times 1$ vector of ones, and $\hat{\beta}_m$ is the $N\times 1$ vector of pre-estimated CAPM betas.

Lets first set up the Second Pass

```{r}
SecondPass <- function(beta, mZ){
  iT = nrow(mZ)
  iN = ncol(mZ)
  mX = cbind(1,beta)
  xxinv = chol2inv(chol(crossprod(mX)))
  xxinvx = tcrossprod(xxinv,mX)
  gamma = NULL; gamsd = NULL; residuals = NULL
  for(iter in 1:iT){
    vy = mZ[iter,]
    tmp = xxinvx%*%vy
    # gamma
    gamma = rbind(gamma, c(tmp))
    s2 = c(crossprod(vy - mX%*%tmp))/iN
    # gammas' standard error
    gamsd = rbind(gamsd, sqrt(diag(s2 * xxinv)))
    residuals = rbind(residuals, vy - mX %*% tmp)
  }
  overall_mean = apply(mZ, 2, mean)  
  tss = sum((mZ - overall_mean)^2)   
  rss = sum(residuals^2)     
  r_squared = 1 - (rss / tss) 
  adj_r_squared = 1 - ((1-r_squared)*(100-1)/(100-1-1))
  
  # gamma0 and market risk premia
  gamma0 = c(gamma[,1]); g0sd = c(gamsd[,1])
  mrprem = c(gamma[,2]); prsd = c(gamsd[,2])
  
  # w tests on pp.30 in slides for lecture 4
  # should be compared with student t with T-1 degrees of freedom
  # or with standard normal if T is large
  wgamma0 = mean(gamma0)/sqrt(sum((gamma0-mean(gamma0))**2)/iT/(iT-1))
  wgamma1 = mean(mrprem)/sqrt(sum((mrprem-mean(mrprem))**2)/iT/(iT-1))
  
  return(list(gamma0=gamma0,g0sd=g0sd,mrprem=mrprem,prsd=prsd,wgamma0=wgamma0,wgamma1=wgamma1,iT=iT, r_squared=r_squared, adj_r_squared=adj_r_squared))
}
```

We again split up the data in the 3 periods, and do the tests for each period, to see how robust the results are over time.
```{r}
# Divide data into sub-periods, 314 time-points in each
subsample1 <- 1:314
subsample2 <- 315:628
subsample3 <- 629:942
subsamples <- list(subsample1,subsample2,subsample3)

pval_wgamma0_v <- numeric(length(subsamples))
wgamma0_v <- numeric(length(subsamples))

pval_wgamma1_v <- numeric(length(subsamples))
wgamma1_v <- numeric(length(subsamples))

Tstat_gamma0_v <- numeric(length(subsamples))
pval_avg_gamma0_v <- numeric(length(subsamples))

Tstat_gamma1_v <- numeric(length(subsamples))
pval_avg_gamma1_v <- numeric(length(subsamples))

vgamma0 <- list()
vgamma1 <- list()

ttestsg0 <- list()
ttestsg1 <- list()

r2 <- numeric(length(subsamples))
adj_r2 <- numeric(length(subsamples))

for (i in 1:length(subsamples)){
  mR = as.matrix(portfolio_m[subsamples[[i]],25:124])
  Rf = as.matrix(portfolio_m[subsamples[[i]],'Tbill'])
  Rm = as.matrix(portfolio_m[subsamples[[i]],'Market'])
  mZ = sweep(mR,1,Rf)
  vZm = Rm - Rf
  
  FPreg <- FirstPass(mZ, vZm)
  SPreg <- SecondPass(FPreg$beta, mZ)
  
  iT <- SPreg$iT
  
  # a)
  wgamma0 <- SPreg$wgamma0
  pval_wgamma0_v[i] <- 2*pt(abs(wgamma0), df=iT-1,lower.tail=FALSE)
  wgamma0_v[i] <- wgamma0
  # b)
  wgamma1 <- SPreg$wgamma1
  pval_wgamma1_v[i] <- pt(wgamma1, df=iT-1, lower.tail=FALSE)
  wgamma1_v[i] <- wgamma1
  # c) 1. gamma0
  gamma0 <- SPreg$gamma0
  Tstat <- (mean(gamma0)-0)/(sd(gamma0)/sqrt(length(gamma0)))
  Tstat_gamma0_v[i] <- Tstat
  pval_avg_gamma0_v[i] <- 2*pt(abs(Tstat), df=length(gamma0)-1,lower.tail=FALSE)
  ttestsg0[[i]] <- t.test(gamma0, alternative=c("two.sided"),mu=0)
  vgamma0[[i]] <- gamma0
  # c) 2. gamma1
  gamma1 <- SPreg$mrprem
  Tstat <- (mean(gamma1)-0)/(sd(gamma1)/sqrt(length(gamma1)))
  Tstat_gamma1_v[i] <- Tstat
  pval_avg_gamma1_v[i] <- pt(wgamma1, df=iT-1, lower.tail=FALSE)
  ttestsg1[[i]] <- t.test(gamma1, alternative=c("greater"),mu=0)
  vgamma1[[i]] <- gamma1
  #goodness of fit
  r2[i] <- SPreg$r_squared
  adj_r2[i] <- SPreg$adj_r_squared
}
```

### (a) Test whether \(\gamma_{0t}=0\) for all t

Note that we do the  assume that $\gamma_{0t}$ are i.i.d. which is not a realistic assumption but it is a compromise.

This is a two tailed t-test at 5% level. 

```{r}
data <- data.frame(
  Metric = c("wgamma0", "p-value"),
  Period_1 = c(round(wgamma0_v[1],4), round(pval_wgamma0_v[1],4)),
  Period_2 = c(round(wgamma0_v[2],4), round(pval_wgamma0_v[2],4)),
  Period_3 = c(round(wgamma0_v[3],4), round(pval_wgamma0_v[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "Test for gamma_0t=0"
)
```

According to theory $\gamma_{0t}$ is zero. In period 1 the p-value is 0.7921 so we fail to reject the null hypothesis that $\gamma_{0t}=0$ for all t, so period 1 is in accordance with the theoretical prediction For period 2 the p-value is 0.1616 and once again we fail to reject the null, so period 2 is also according to theory. For the last period the obtained p-value is less than 0.05 and therefore we reject the null that $\gamma_{0t}=0$ for all t. So period 3 is not consistent with theory. Summarizing, the data is in accordance with theory in period 1 and 2, but not in period 3. 

### (b) Test whether \(\gamma_{1t}>0\) for all t

So $\gamma_1$ is the risk premia and according to theory it is positive, i.e. we should reject that it is zero or less. So we test the null $\gamma_{1t}\le0$ for all t because then we get the alternative that is strictly larger, i.e. $\gamma_{1t}>0$. Here we conduct a one-sided t-test. Note that we do the  assume that $\gamma_{1t}$ are i.i.d. which is not a realistic assumption but it is a compromise.

```{r}
data <- data.frame(
  Metric = c("wgamma1", "p-value"),
  Period_1 = c(round(wgamma1_v[1],4), round(pval_wgamma1_v[1],4)),
  Period_2 = c(round(wgamma1_v[2],4), round(pval_wgamma1_v[2],4)),
  Period_3 = c(round(wgamma1_v[3],4), round(pval_wgamma1_v[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "Test for gamma_1t>0 (H_0:gamma_1t<=0)"
)
```


Theory says we should reject $\gamma_{1t}$ is zero or less, because theory says it should be positive, because the investor should get some positive return in excess of the risk-free rate, as a reward for taking on more risk. We can see that for period 1, we reject the null of $\gamma_{1t}\le0$ for all t at a 5% significance level, so we accept the alternative of $\gamma_{1t}>0$. So period 1 is according to theory. For period 2 and 3, we accept the null that the risk premia is less than or equal to zero $\gamma_{1t}\le0$ actually. This finding in period 2 and 3 of the risk premia contradicts the theory.


### (c) Test whether \(\bar{\gamma}_1 = T^{-1}\sum_{t=1}^T \hat{\gamma}_{1t} > 0\) and \(\bar{\gamma}_0 = T^{-1}\sum_{t=1}^T \hat{\gamma}_{0t} = 0\)

First we test $\bar{\gamma}_0 = T^{-1}\sum_{t=1}^T \hat{\gamma}_{0t} = 0$. Again we assume that $\gamma_{0t}$ are i.i.d. which is not a realistic assumption but it is a compromise.
```{r}
data <- data.frame(
  Metric = c("sample mean", "t-stat", "p-value"),
  Period_1 = c(round(mean(vgamma0[[1]]),4), round(Tstat_gamma0_v[1],4), round(pval_avg_gamma0_v[1],4)),
  Period_2 = c(round(mean(vgamma0[[2]]),4), round(Tstat_gamma0_v[2],4), round(pval_avg_gamma0_v[2],4)),
  Period_3 = c(round(mean(vgamma0[[3]]),4), round(Tstat_gamma0_v[3],4), round(pval_avg_gamma0_v[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "Test for gamma_0t=0"
)
```
Wee see that we reject, some are not zero.

Now we test $\bar{\gamma}_1 = T^{-1}\sum_{t=1}^T \hat{\gamma}_{1t} > 0$.

Again we assume that $\gamma_{1t}$ are i.i.d. which is not a realistic assumption but it is a compromise.
```{r}
data <- data.frame(
  Metric = c("sample mean", "t-stat", "p-value"),
  Period_1 = c(round(mean(vgamma1[[1]]),4), round(Tstat_gamma1_v[1],4), round(pval_avg_gamma1_v[1],4)),
  Period_2 = c(round(mean(vgamma1[[2]]),4), round(Tstat_gamma1_v[2],4), round(pval_avg_gamma1_v[2],4)),
  Period_3 = c(round(mean(vgamma1[[3]]),4), round(Tstat_gamma1_v[3],4), round(pval_avg_gamma1_v[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "Test for gamma_1t>0 (H_0:gamma_1t<=0)"
)
```
We assume the gammas are i.i.d. which is a strong assumption and not realistic. Even when we average the t-statistics for all the periods we observe the same findings as when we checked the assumption for each period individually. We reject the null when we test if $\gamma_{0t}=0$ for period 3. When testing for $\gamma_{1t}<=0$ we reject the test in the first period. 

Now we evaluate the goodness-of-fit.
```{r}
data <- data.frame(
  Metric = c("R^2", "adj. R^2"),
  Period_1 = c(round(r2[1],4), round(adj_r2[1],4)),
  Period_2 = c(round(r2[2],4), round(adj_r2[2],4)),
  Period_3 = c(round(r2[3],4), round(adj_r2[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "Goodness of fit"
)
```
Goodness-of-fit provide evidence that for period 1 the model explains around 68\% of the variability. For period 2 we see a higher $R^2$ around 73\% and for period 3 we observe $R^2$ around 75\%. We see very similar results for the adjusted $R^2$ to the standard $R^2$.

We observe that the results from the hypothesis testing fluctuates over time and in some periods contradict the theory of CAPM. Given the findings that the results fluctuate there seems to be evidence that the relationship is sensitive to market conditions or that there might be some omitted variables. 

## 3. Generate two variables indicating the corresponding underlying size and book-to-market decile for each portfolio over the cross-section.

### (a) Plot the corresponding size and book-to-market decile numbers against the average returns of the corresponding portfolios. What do you find? Do you expect that size and book-to-market effects have explanatory power in the cross-sectional equation (1)?

We start by generating two factor variables for size and book-to-market which we will use to plot the average returns.

```{r}
# The factor variables where computed in A.4 (c).

avg_ret_df <- data.frame(
  Size = as.factor(size_decile),
  BookToMarket = as.factor(book_to_market_decile),
  avg_ret = colMeans(portfolio_m[,25:124])
)
```

### (a) Plot the corresponding size and book-to-market decile numbers against the average returns of the corresponding portfolios. What do you find? Do you expect that size and book-to-market effects have explanatory power in the cross-sectional equation (1)?

```{r}
ggplot(avg_ret_df, aes(x = Size, y = BookToMarket, fill = avg_ret)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "darkblue") +
  labs(title = "Heatmap of Average Returns by Size and Book-to-Market",
       x = "Size Decile",
       y = "Book-to-Market Decile",
       fill = "Average Returns") +
  theme_minimal()
```
In the figure above we have plotted a heat map of average returns against size and book to market. What we see is that smaller size and larger book-to-market generally have higher average returns compared to portfolios of larger size and lower book to market. However smaller size and and lower book-to-market seems to yield lower average returns, so the relationship is not entirely clear. Based on this plot it seems like book-to-market more strongly affect average returns compared to size.

Based on this we believe that book-to-market effects will have explanatory power in the cross-sectional equation (1). Size could also have explanatory power, we are however less certain about this hypothesis.


### (b) Augment equation (1) by these two variables and analyze whether they have explanatory power beyond the CAPM betas. Interpret your findings.

For this task we will log transform the size and book-to-market deciles:


$$
Z_t = \gamma_{0t} \iota + \gamma_{1t}\hat{\beta}_{m} + \gamma_{2t}log(Size)+\gamma_{3t}log(BtM) + \eta_t
$$
We use the log transformed deciles for two reasons: The exercise states that we should generate \textbf{two} variables indicating the corresponding underlying size and book-to-market decile for each portfolio over the cross-section. This rules out using the constructed factors as is since this would require us to generate 18 dummy variables. The next reason is that we can not employ the variables as continuous as this would imply a linear relationship between the deciles and returns which is likely not true. It is more likely that there is a diminishing effect of size and book-to-market on returns, i.e. moving from size decile 1 to 2 might have a greater impact on returns compared to decile 9-10, and similarly for book-to-market. 

Both of these problems are solved by using log transformed deciles rather than dummy variables.

In order to analyze wether they have explanatory power or not, we will compute the $R^2$ and adjusted $R^2$, as well as a Wald-test of $H_0: \gamma \leq 0$ vs. $H_1: \gamma > 0$.

```{r,echo=F}
SecondPass_2 <- function(beta, mZ, size, bm){
  iT = nrow(mZ)
  iN = ncol(mZ)
  mX = cbind(1,beta, size, bm)
  xxinv = chol2inv(chol(crossprod(mX)))
  xxinvx = tcrossprod(xxinv,mX)
  gamma = NULL; gamsd = NULL; residuals = NULL
  for(iter in 1:iT){
    vy = mZ[iter,]
    tmp = xxinvx%*%vy
    # gamma
    gamma = rbind(gamma, c(tmp))
    s2 = c(crossprod(vy - mX%*%tmp))/iN
    # gammas' standard error
    gamsd = rbind(gamsd, sqrt(diag(s2 * xxinv)))
    residuals = rbind(residuals, vy - mX %*% tmp)
  }
  overall_mean = apply(mZ, 2, mean)  
  tss = sum((mZ - overall_mean)^2)   
  rss = sum(residuals^2)     
  r_squared = 1 - (rss / tss) 
  adj_r_squared = 1 - ((1-r_squared)*(100-1)/(100-3-1))
  
  # gamma0 and market risk premia
  gamma0 = c(gamma[,1]); g0sd = c(gamsd[,1])
  mrprem = c(gamma[,2]); prsd = c(gamsd[,2])
  gamma_size = c(gamma[, 3])  # Coefficient for logSize
  gamma_bm = c(gamma[, 4])  # Coefficient for logBM
  
  
  # w tests on pp.30 in slides for lecture 4
  # should be compared with student t with T-1 degrees of freedom
  # or with standard normal if T is large
  wgamma0 = mean(gamma0)/sqrt(sum((gamma0-mean(gamma0))**2)/iT/(iT-1))
  wgamma1 = mean(mrprem)/sqrt(sum((mrprem-mean(mrprem))**2)/iT/(iT-1))
  wgamma_size = mean(gamma_size) / sqrt(sum((gamma_size - mean(gamma_size))**2) / iT / (iT - 1))
  wgamma_bm = mean(gamma_bm) / sqrt(sum((gamma_bm - mean(gamma_bm))**2) / iT / (iT - 1))
  
  return(list(gamma0=gamma0,g0sd=g0sd,mrprem=mrprem,gamma_size=gamma_size, gamma_bm=gamma_bm,  prsd=prsd,wgamma0=wgamma0,wgamma1=wgamma1,wgamma_size=wgamma_size,wgamma_bm=wgamma_bm, iT=iT, r_squared=r_squared, adj_r_squared=adj_r_squared))
}

mR = as.matrix(portfolio_m[,25:124])
Rf = as.matrix(portfolio_m[,'Tbill'])
Rm = as.matrix(portfolio_m[,'Market'])
mZ = sweep(mR,1,Rf)

vZm = Rm - Rf

beta <- FirstPass(mZ, vZm)$beta
ret = SecondPass_2(beta=beta, mZ=mZ, log(size_decile), log(book_to_market_decile))
re = SecondPass(beta=beta, mZ=mZ)

r2 <- data.frame(`Original model`=c(re$r_squared, re$adj_r_squared),
                 `Augmented model`=c(ret$r_squared, ret$adj_r_squared),
                 row.names = c("R2", "adj.R2"))
kable(r2, digits=4, caption="Comparison of R Squared between the original second pass regression and the regression including the log transformed Size and Book-to-Market deciles.")
```
We see in the table above that $R^2$ increases somewhat when we include the log transformed size and book-to-market deciles. Since we increase the number of coefficients in the model we also include the adjusted $R^2$ which penalizes based on the number of coefficients. We see that the adjusted $R^2$ is also slightly larger in the augmented model compared to the original model. 

Based on this, we come to the conclusion that the log transformed size and book-to-market deciles have some explanatory power.


```{r, echo=F}
wgamma_size <- ret$wgamma_size
pval_wgamma_s <- pt(wgamma_size, df=nrow(mZ)-1, lower.tail=FALSE)
wgamma_bm <- ret$wgamma_bm
pval_wgamma_bm <- pt(wgamma_bm, df=nrow(mZ)-1, lower.tail=FALSE)

results <- data.frame(Size=c(wgamma_size, pval_wgamma_s),
                      Book_to_Market = c(wgamma_bm, pval_wgamma_bm),
                      row.names = c("Test statistic", "P-value")
)
kable(results, digits=4, caption = "Test (separately) whether $gamma_{2t}>0$ and $gamma_{2t}>0$ for all t")
```
In the table above you see the Wald-test statistics and their corresponding p-values (same test as in B.2 (b)). Here we  test (separately) whether $\gamma_{2t}>0$ and $\gamma_{2t}>0$ for all t. We see that the p-value for log(Size) is large, meaning that we cannot reject the null hypothesis $H_0: \gamma_{2t}\leq 0$. The p-value for log(book-to-market) is very close to zero and we reject the null hypothesis at $\alpha=0.05$. From these results we infer that book-to-market has significant explanatory power while size do not, meaning that book-to-market explains variation in returns that is not explained by market risk premium. It is likely that the inclusion of book-to-market in the model is the reason for the increased $R^2$.





```{r}
iT <- nrow(mZ)
R2 <- numeric(nrow(mZ))
for (iter in 1:iT){
  fit <- lm(formula = mZ[iter, ] ~ (tmp$beta))
  R2[iter] <- summary(fit)$r.squared
}
```