---
title: "Report for PS3"
author:
- Mark Becker, Erik Lillrank & Vilim Nedic
date: ''
output:
  pdf_document:
    keep_tex: true
  df_print: kable
  html_document:
    df_print: paged
  word_document: default
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
  - \usepackage{multirow}
  - \usepackage{caption}
  - \usepackage{subcaption}
  - \usepackage{adjustbox}
toc: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(FE)
library(knitr)
library(patchwork)
library(kableExtra)
library(dplyr)
library(psych)
library(car)
data("portfolio_m")
```

# A Size and book-to-market effects
Use the data set `portfolio_m` consisting of returns of U.S. stock portfolios built on size and book-to-market ratio according to Fama and French (1993, 1996). In the following you have to test the validity of the CAPM based on these portfolios.

## 1. Analyze the descriptive statistics of the returns of the different portfolios. Do you find systematic differences in dependence of size and the book-to-market ratio?

```{r descriptive, echo=F}
descriptive_stats <- describe(portfolio_m[,5:24])[,c("mean", "sd", "skew", "kurtosis", "min", "max")]
kable(descriptive_stats, digits = 3) # Har jag tolkat rätt att det är ME1-ME10 och MEBE1-MEBE10 som är portfolios?
```
What we see in the table above is that the smaller firms (ME1-ME3) have higher average returns (larger means) and volatility (larger standard deviations) than the larger firms (e.g. ME10). Looking at the book-to-market effect, the higher book-to-market (e.g. MEBE10) portfolios exhibit higher average returns (larger means) and volatility (larger standard deviations) compared to the lower book-to-market (MEBE1) portfolios. For the ME portfolios we see positive skewness that is decreasing with the size, i.e. smaller firms are more positively skewed, indicating occasional extreme positive returns, and this seems to decrease with size. For MEBE portfolios, they seem to be more symmetric for the smaller book-to-market portfolios with some slightly negative skewness. But then from the 4th decile and up, instead it seems that skewness increases (positive) with larger book-to-market size. The smaller firms and higher book-to-market portfolios have high kurtosis, suggesting heavy-tailed return distributions. Looking at the minimum and maximum values we also see that for the smaller firms and higher book-to-market portfolios there are extreme returns. From the descriptive statistics we see evidence of both the size effect and the value effect.


## 2. For all individual size and book-to-market portfolios as well as the market portfolio(s), compute the corresponding excess returns. Then, estimate the CAPM for selected portfolios and answer the following questions:

We start by computing the excess returns, which are given by:

$$
Z_{it} = R_{it}-R_f \quad and \quad Z_{mt}=R_{mt}-R_f
$$

```{r}
excess_returns <- portfolio_m[,c(3,5:24)]-portfolio_m$Tbill
```
The next step is the fit the following regression equation:

$$
Z_{it}=\alpha_i + \beta_i Z_{mt} + \epsilon_{it}
$$

Implementing in `R` using a simple `for`-loop:

```{r}
results <- data.frame(
  Portfolio = character(),
  Alpha = numeric(),
  Beta = numeric(),
  R2 = numeric(),
  StdErrAlpha = numeric(),
  StdErrBeta = numeric(),
  PValueAlpha = numeric(),
  PValueBeta = numeric(),
  stringsAsFactors = FALSE
)

portfolios <- colnames(excess_returns)[2:21]
for (i in portfolios){
  ER <- excess_returns[[i]]
  capm_model <- lm(ER ~ excess_returns$Market)
  
  alpha <- coef(capm_model)["(Intercept)"]
  beta <- coef(capm_model)["excess_returns$Market"]
  r_squared <- summary(capm_model)$r.squared
  std_err_alpha <- coef(summary(capm_model))["(Intercept)", "Std. Error"]
  std_err_beta <- coef(summary(capm_model))["excess_returns$Market", "Std. Error"]
  p_value_alpha <- coef(summary(capm_model))["(Intercept)", "Pr(>|t|)"]
  p_value_beta <- coef(summary(capm_model))["excess_returns$Market", "Pr(>|t|)"]
  
  results <- rbind(
    results,
    data.frame(
      Portfolio = i,
      Alpha = alpha,
      Beta = beta,
      R2 = r_squared,
      StdErrAlpha = std_err_alpha,
      StdErrBeta = std_err_beta,
      PValueAlpha = p_value_alpha,
      PValueBeta = p_value_beta
    )
  )
}

rownames(results) <- NULL
kable(results, digits = 3, caption = "Estimated CAPM for the portfolios", label = "tab:capm1")
```


### (a) Test the validity of the CAPM for the individual size and book-to-market portfolios. Can you confirm the CAPM relationship across the cross-section of size and book-to-market portfolios?

What we will be inspecting in order to answer this question is $\alpha$ and the corresponding p-value. In CAPM, $\alpha$ represents the excess return not explained by the market. For CAPM to hold, $\alpha$ should be statistically insignificant i.e. close to zero/we can not reject that it is 0, and $\beta$ should capture the cross-sectional variation of expected excess returns.

In table \ref{tab:capm1} we see that $\alpha$ is only statistically significant at 10\% for MEBE5 and MEBE8, with only MEBE8 being significant at 5\%. We see that we can not reject $\alpha$ being zero for all other portfolios, however we do see that the estimates although insignificant are higher for smaller portfolios and for higher book-to-market portfolios. Based on these results it seems that CAPM is valid for most of the portfolios, however it holds better for portfolios of larger firms and lower book-to-market portfolios. #spelar storleken på estimatet någon roll om vi ändå inte kan rejecta att den är 0?

### (b) Is there a systematic relation between the estimated market beta and size as well as the book-to-market ratio? Interpret your findings.

Looking at the $\beta$'s in table \raf{tab:capm1}, we see that the portfolios of smaller firms tend to have higher $\beta$'s while the portfolios of larger firms have lower $\beta$'s. This indicates that the returns of smaller firms are more volatile than the returns of larger firms. Also ME10 has a $\beta<1$, which indicates that the largest firms have returns less volatile than the market. The rest of the ME have $\beta >1$, meaning they have returns more volatile than the market. We also see that $\beta$'s are higher for highest book-to-market portfolios compared to lower book-to-market portfolios. This indicates that the higher book-to-market portfolios have more volatile returns than the lower book-to-market portfolios. For the ME portfolios some have $\beta<1$ and some $\beta>1$ so some are more volatile than the market and some are less volatile.

### (c) Is there a systematic relation between the \($R^2\) and market capitalization as well as book-to-market ratio? What does this mean?

Looking at the $R^2$'s, we see that it is lower for the lower market capitalization portfolios compared to the higher market capitalization portfolios, This suggests that CAPM captures most of the variation in excess return for the higher market capitalization portfolios while the explanatory power is weaker for the smaller portfolios. 

Looking at the relation between $R^2$ and the book-to-market ratio, we see that the explanatory power is stronger for the portfolios of lower book-to-market ratio compared to those with higher.

In conclusion, these results suggests that CAPM performs well for larger stocks and for lower book-to-market portfolios, but for smaller portfolios and higher book-to-market portfolios, the $\alpha$'s and lower $R^2$ suggests that other factors than market risk could be driving returns.

## 3. Estimate the CAPM jointly for the complete set of size portfolios, book-to-market portfolios as well as portfolios built on the intersections of size and book-to-market deciles. Test for joint significance of the intercept terms using the F-test.

```{r, include=F}
# Tror att detta är fel men lämnar det sålänge, se nästa chunk.


# Stack data for joint estimation
portfolio_returns <- portfolio_m[, 5:124] #tror det ska vara alla 124 alltså 5:124
excess_returns <- as.vector(as.matrix(portfolio_returns - portfolio_m$Tbill))
market_excess <- rep(portfolio_m$Market - portfolio_m$Tbill, ncol(portfolio_returns))
portfolio_labels <- rep(colnames(portfolio_returns), each = nrow(portfolio_returns))

# Create a data frame for pooled regression
pooled_data <- data.frame(
  excess_returns = excess_returns,
  market_excess = market_excess,
  portfolio = factor(portfolio_labels)
)

# Fit a pooled regression with portfolio dummy variables
pooled_model <- lm(excess_returns ~ market_excess + portfolio, data = pooled_data)

# Test joint significance of intercepts
f_test <- linearHypothesis(pooled_model, hypothesis.matrix = grep("^portfolio", names(coef(pooled_model)), value = TRUE))
print(f_test)

```
In this question we will use the `FamaMacbeth0()` function which was given in the assignment in order to estimate the joint CAPM and test for joint significance of the intercept terms using the F-test. So we test the following for the vector of intercept terms

$$
\begin{aligned}
H_0:\alpha &=0\\
H_a:\alpha &\neq0
\end{aligned}
$$
on a usual 5% significance level. The test used is the F-test proposed by Gibbons/Ross/Shanken 1989:

$$
J_1 = \frac{T-N-1}{N}\left[1+\frac{\hat{\mu}_m^2}{\hat{\sigma}^2_m} \right]^{-1} \hat{\alpha}^{\prime}\hat{\Sigma}^{-1}\hat{\alpha}\sim F_{N,T-N-1}
$$
where
$$
x = \sqrt{T}\left[1+\frac{\hat{\mu}_m^2}{\hat{\sigma}^2_m}\right]^{-1}\hat{\alpha},\;\; A=T\hat{\Sigma}, \;\; m=N, \;\; n=T-2
$$

```{r, echo=F}
FamaMacbeth0 <- function(mZ, vZm)
{
  iT = nrow(mZ)
  iN = ncol(mZ)
  
  # First Pass
  mX = cbind(1,vZm)
  pars = chol2inv(chol(crossprod(mX)))%*%crossprod(mX,mZ)
  alpha = c(pars[1,])
  # estimated betas
  beta = c(pars[2,])
  # sample mean of each excess return
  mu = apply(mZ,2,mean)
  # sample mean of the market excess return
  mum = mean(vZm)
  # variance of the market excess return
  sigm2 = c(crossprod(vZm-mum))/iT
  # residules
  me = mZ-mX%*%pars
  # covariance matrix of the residules
  Sigma = crossprod(me)/iT
  
  # do the test on pp.24 & 25 in slides for lecture 4
  tmp = c(t(alpha)%*%chol2inv(chol(Sigma))%*%alpha)/(1+mum^2/sigm2)
  
  # Gibbons/Ross/Shanken (1989)
  J1 = tmp*(iT-iN-1)/iN
  jpval = 1-pf(J1,df1=iN,df2=iT-iN-1)
  
  # Wald
  W = tmp*iT
  wpval = 1-pchisq(W,df=iN)
  
  # modified LR, Jobson/Korkie (1982)
  mX = matrix(vZm,iT,1)
  pars = chol2inv(chol(crossprod(mX)))%*%crossprod(mX,mZ)
  me = mZ-mX%*%pars
  # covariance matrix of the residules
  SigmaR = crossprod(me)/iT
  LR = (sum(log(eigen(SigmaR)$values))-sum(log(eigen(Sigma)$values)))*(iT-iN/2-2)
  lrpval = 1-pchisq(LR,df=iN)
  
  
  # Second Pass
  mX = cbind(1,beta)
  xxinv = chol2inv(chol(crossprod(mX)))
  xxinvx = tcrossprod(xxinv,mX)
  gamma = NULL; gamsd = NULL
  for(iter in 1:iT){
    vy = mZ[iter,]
    tmp = xxinvx%*%vy
    # gamma
    gamma = rbind(gamma, c(tmp))
    s2 = c(crossprod(vy - mX%*%tmp))/iN
    # gammas' standard error
    gamsd = rbind(gamsd, sqrt(diag(s2 * xxinv)))
  }
  
  # gamma0 and market risk premia
  gamma0 = c(gamma[,1]); g0sd = c(gamsd[,1])
  mrprem = c(gamma[,2]); prsd = c(gamsd[,2])
  
  # w tests on pp.30 in slides for lecture 4
  # should be compared with student t with T-1 degrees of freedom
  # or with standard normal if T is large
  wgamma0 = mean(gamma0)/sqrt(sum((gamma0-mean(gamma0))**2)/iT/(iT-1))
  wgamma1 = mean(mrprem)/sqrt(sum((mrprem-mean(mrprem))**2)/iT/(iT-1))
  
  return(list(alpha=alpha,beta=beta,J1=c(J1,jpval),W=c(W,wpval),mLR=c(LR,lrpval),
              gamma0=gamma0,g0sd=g0sd,mrprem=mrprem,prsd=prsd,wgamma0=wgamma0,wgamma1=wgamma1))
}

mR = as.matrix(portfolio_m[,5:124])
Rf = as.matrix(portfolio_m[,'Tbill'])
Rm = as.matrix(portfolio_m[,'Market'])
mZ = sweep(mR,1,Rf)

vZm = Rm - Rf

ret = FamaMacbeth0(mZ=mZ, vZm=vZm)
J1_stat <- ret$J1[1]
p_value <- ret$J1[2]

J1_results <- data.frame(
  Test = c("F-test Statistic (J1)", "P-value"),
  Value = c(round(ret$J1[1], 4), round(ret$J1[2], 4))
)
kable(J1_results, caption = "F-test Results for Joint Significance of Intercepts", label="tab:Ftest")
```
In table \ref{tab:Ftest} we see the results from the F-test. We see in the table that the p-value is very close to zero, so we can see that we reject the null of $\alpha=$ on a 5% (also 1%) significance level. The interpretation is that we have strong evidence that at least 1 of the intercept terms $\alpha_i$ in the intercept vector $\alpha$ is significantly different from zero. So we can on the basis of this test conclude that CAPM does not seem to hold, when we estimate it jointly for all the portfolios.

## 4. Use the 100 portfolios built on the intersections of size and book-to-market deciles and divide the sample in appropriate sub-periods. Specify a CAPM which allows for period-specific betas and intercept terms. Estimate the model for these portfolios.

We chose to divide the sample into three even sub-periods. In order to include period-specific betas and intercept terms, we computed dummy variables for periods two and three. These dummy variables will act as our period specific intercepts, we did not include a dummy for the first period as this will cause multi-collinearity. The period specific intercepts are then given by:

$$
\begin{aligned}
\alpha_{Period\;1} &=\alpha \\
\alpha_{Period\;2} &=\alpha+\gamma_2 \\
\alpha_{Period\;3} &=\alpha +\gamma_3\\
\end{aligned}
$$
With $\gamma$ denoting the coefficients for the dummy variables $D_2$ and $D_3$. 

In order to include period-specific betas, we include interaction terms between the period dummies and the market excess:

$$
\delta_4(D_2*Z_{mt}) \quad and \quad \delta_5(D_3*Z_{mt})
$$
Such that the CAPM model is:

$$
Z_{t}=\alpha_t+\beta_1Z_{mt}+\gamma_2+\gamma_3+\delta_4(D_2*Z_{mt}) + \delta_5(D_3*Z_{mt})+\epsilon_{t}
$$

```{r}

# Vet inte om det här är rätt metod


# Divide data into sub-periods, 314 time-points in each
subsample1 <- 1:314
subsample2 <- 315:628
subsample3 <- 629:942

#Create dummies
portfolio_m$Period2 <- 0
portfolio_m$Period3 <- 0
portfolio_m[subsample2,]$Period2 <- portfolio_m[subsample2,]$Period2 + 1
portfolio_m[subsample3,]$Period3 <- portfolio_m[subsample3,]$Period3 + 1

excess_returns <- portfolio_m[,c(3,25:124)]-portfolio_m$Tbill



results <- data.frame(
  Portfolio = character(),
  Alpha = numeric(),
  Beta = numeric(),
  Period2Coef = numeric(),
  Period3Coef = numeric(),
  InteractionPeriod2Market = numeric(),
  InteractionPeriod3Market = numeric(),
  R2 = numeric(),
  adj_R2 = numeric(),
  StdErrAlpha = numeric(),
  StdErrBeta = numeric(),
  PValueAlpha = numeric(),
  PValueBeta = numeric(),
  PValuePeriod2 = numeric(),
  PValuePeriod3 = numeric(),
  PValueInteractionPeriod2Market = numeric(),
  PValueInteractionPeriod3Market = numeric(),
  stringsAsFactors = FALSE
)

portfolios <- colnames(excess_returns)[2:101]
# Loop through each portfolio
portfolios <- colnames(excess_returns)[2:101]
for (i in portfolios) {
  ER <- excess_returns[[i]]
  
  # Fit CAPM model with period-specific betas and intercepts (interaction terms)
  capm_model <- lm(ER ~ excess_returns$Market + portfolio_m$Period2 + portfolio_m$Period3 + 
                    portfolio_m$Period2 * excess_returns$Market + portfolio_m$Period3 * excess_returns$Market)
  
  # Extract coefficients, p-values, and statistics
  alpha <- coef(capm_model)["(Intercept)"]
  beta <- coef(capm_model)["excess_returns$Market"]
  period2_coef <- coef(capm_model)["portfolio_m$Period2"]
  period3_coef <- coef(capm_model)["portfolio_m$Period3"]
  interaction_period2_market <- coef(capm_model)["excess_returns$Market:portfolio_m$Period2"]
  interaction_period3_market <- coef(capm_model)["excess_returns$Market:portfolio_m$Period3"]
  
  r_squared <- summary(capm_model)$r.squared
  adj_r_squared <- summary(capm_model)$adj.r.squared
  std_err_alpha <- coef(summary(capm_model))["(Intercept)", "Std. Error"]
  std_err_beta <- coef(summary(capm_model))["excess_returns$Market", "Std. Error"]
  
  # Extract p-values
  p_value_alpha <- coef(summary(capm_model))["(Intercept)", "Pr(>|t|)"]
  p_value_beta <- coef(summary(capm_model))["excess_returns$Market", "Pr(>|t|)"]
  p_value_period2 <- coef(summary(capm_model))["portfolio_m$Period2", "Pr(>|t|)"]
  p_value_period3 <- coef(summary(capm_model))["portfolio_m$Period3", "Pr(>|t|)"]
  p_value_interaction_period2_market <- coef(summary(capm_model))["excess_returns$Market:portfolio_m$Period2", "Pr(>|t|)"]
  p_value_interaction_period3_market <- coef(summary(capm_model))["excess_returns$Market:portfolio_m$Period3", "Pr(>|t|)"]
  
  # Store results in data frame
  results <- rbind(
    results,
    data.frame(
      Portfolio = i,
      Alpha = alpha,
      Beta = beta,
      Period2Coef = period2_coef,
      Period3Coef = period3_coef,
      InteractionPeriod2Market = interaction_period2_market,
      InteractionPeriod3Market = interaction_period3_market,
      R2 = r_squared,
      adj_R2 = adj_r_squared,
      StdErrAlpha = std_err_alpha,
      StdErrBeta = std_err_beta,
      PValueAlpha = p_value_alpha,
      PValueBeta = p_value_beta,
      PValuePeriod2 = p_value_period2,
      PValuePeriod3 = p_value_period3,
      PValueInteractionPeriod2Market = p_value_interaction_period2_market,
      PValueInteractionPeriod3Market = p_value_interaction_period3_market
    )
  )
}

# Display results using kable
rownames(results) <- NULL

period_spec <- as.data.frame( cbind(results$Period2Coef, results$PValuePeriod2, results$Period3Coef, results$PValuePeriod3, results$InteractionPeriod2Market, results$PValueInteractionPeriod2Market, results$InteractionPeriod3Market, results$PValueInteractionPeriod3Market))

colnames(period_spec) <- c("Period2", "PValue_Period2", "Period3", "PValue_Period3", 
                           "Period2&Market", "PValue_Period26Market", 
                           "Period3&Market", "PValue_Period3&Market")
rownames(period_spec) <- colnames(excess_returns)[2:101]

kable(head(period_spec), digits = 3, caption = "Estimated CAPM for the portfolios", label = "tab:capm3")
```
In the table above, you see the coefficients and their corresponding p-values for the first few portfolios.


### (a) Do you find statistically significant evidence for time-varying market betas and intercept terms?

We can perform the Chow Test. We estimate the full sample CAPM as

$$
Z_{t}=\alpha + \beta Z_{mt} + \epsilon_{t}
$$
We can split up the data into two groups, i.e. the first half of the data and the second half like

$$
\begin{aligned}
Z_{t}=\alpha_1 + \beta_1 Z_{mt} + \epsilon_{t}\\
Z_{t}=\alpha_2 + \beta_2 Z_{mt} + \epsilon_{t}
\end{aligned}
$$
The null of the Chow test asserts that $\alpha_1=\alpha_2,\beta_1=\beta_2$, under the assumption that $\epsilon_t \overset{\mathrm{iid}}{\sim} N(0,\sigma^2)$. Then we have the Chow test statistic

$$
\frac{(S_C-(S_1+S_2))/k}{(S_1+S_2)/(N_1+N_2-2k)} \sim F_{k,N_1+N_2-2k}
$$
where $S_C$ is the sum of squared residuals from the full data sample, $S_1$ be the sum of squared residuals from the first group, $S_2$ be the sum of squared residuals from the second group, $N_1$ and $N_2$ are the number of observations in each group and $k$ is the total number of parameters estimated.

```{r}
# Chow test

#divide the data into 2 groups, first half and second half
t1 <- 1:471
t2 <- 472:942

# full sample data
excess_returnsMarket <- as.matrix(portfolio_m[,3]-portfolio_m$Tbill)
excess_returnsR11 <- as.matrix(portfolio_m[,25]-portfolio_m$Tbill) #example R11, column 25

# Split the excess returns into two groups based on indices t1 and t2
excess_returnsMarket_t1 <- excess_returnsMarket[t1]
excess_returnsMarket_t2 <- excess_returnsMarket[t2]

excess_returnsR11_t1 <- excess_returnsR11[t1]
excess_returnsR11_t2 <- excess_returnsR11[t2]

### chow test function ###
my.chow.test <- function(y1,x1,y2,x2){
  
  full_sample_fit <- lm(c(y1,y2)~c(x1,x2))
  
  S_C <- sum(full_sample_fit$residuals^2)
  k <- length(full_sample_fit$coefficients)
  
  N_1 <- length(y1)
  N_2 <- length(y2)
  
  group_1_fit <- lm(y1~x1)
  group_2_fit <- lm(y2~x2)
  
  S_1 <- sum(group_1_fit$residuals^2)
  S_2 <- sum(group_2_fit$residuals^2)
  
  Chow_test_stat <- ((S_C-(S_1+S_2))/k)/((S_1+S_2)/(N_1+N_2-2*k))
  
  pval = 1-pf(Chow_test_stat,df1=k,df2=N_1+N_2-2*k)
  
  return(c(Fstat=Chow_test_stat, df1=k,df2=N_1+N_2-2*k, pvalue=pval))
}


#install.packages("gap")
library(gap)
y1 <- excess_returnsR11_t1
y2 <- excess_returnsR11_t2
x1 <- excess_returnsMarket_t1
x2 <- excess_returnsMarket_t2

my.chow.test(y1,x1,y2,x2)
chow.test(y1,x1,y2,x2) #same results as the package


### now try for all ###
#divide the data into 2 groups, first half and second half
t1 <- 1:471
t2 <- 472:942

ER_M <- as.matrix(portfolio_m[,3]-portfolio_m$Tbill) #full sample
x1 <- ER_M[t1] #period 1
x2 <- ER_M[t2] #period 2

# 25:124 all Rx(x)y(y) portfolios
pvals <- numeric(length(25:124))

for (i in 25:124){
  ER <- as.matrix(portfolio_m[,i]-portfolio_m$Tbill)
  y1 <- ER[t1]
  y2 <- ER[t2]
  pvals[i-24] <- my.chow.test(y1,x1,y2,x2)[4] #p-value
}

library(ggplot2)
pvalsdf <- data.frame(pvals)
plot <- ggplot(pvalsdf, aes(x=pvals)) + 
  geom_histogram()

plot + geom_vline(aes(xintercept=0.05),
            color="blue", linetype="dashed", linewidth=1)

length(pvals)
sum(pvals<0.05)
```

For 80 out of the 100 portfolios, we reject the null hypothesis that $\alpha_1=\alpha_2,\beta_1=\beta_2$ at a 5% level, indicating that the vast majority of the portfolios seems to have time-varying market betas and intercept terms.


### (b) Analyze wether the inclusion of period-specific effects does increase the model's goodnes-of-fit.

In order to answer this question, we will look at the coefficient of determination ($R^2$) of the extended CAPM and the CAPM without period-specific effects. This is calculated as:

$$
R^2 = 1-\frac{SS_{res}}{SS_{tot}}
$$
Where SS denotes the sum of squares of the residuals and the total sum of squares. As including more variables always increase $R^2$, we will also investigate the adjusted $R^2$ which penalizes based on number of coefficients.


```{r, include=F}
results2 <- data.frame(
  Portfolio = character(),
  Alpha = numeric(),
  Beta = numeric(),
  R2 = numeric(),
  adj_R2 = numeric(),
  StdErrAlpha = numeric(),
  StdErrBeta = numeric(),
  PValueAlpha = numeric(),
  PValueBeta = numeric(),
  stringsAsFactors = FALSE
)

for (i in portfolios) {
  ER <- excess_returns[[i]]
  
  # Fit CAPM model with period-specific betas and intercepts (interaction terms)
  capm_model <- lm(ER ~ excess_returns$Market)
  
  # Extract coefficients, p-values, and statistics
  alpha <- coef(capm_model)["(Intercept)"]
  beta <- coef(capm_model)["excess_returns$Market"]
  
  r_squared <- summary(capm_model)$r.squared
  adj_r_squared <- summary(capm_model)$adj.r.squared
  std_err_alpha <- coef(summary(capm_model))["(Intercept)", "Std. Error"]
  std_err_beta <- coef(summary(capm_model))["excess_returns$Market", "Std. Error"]
  
  # Extract p-values
  p_value_alpha <- coef(summary(capm_model))["(Intercept)", "Pr(>|t|)"]
  p_value_beta <- coef(summary(capm_model))["excess_returns$Market", "Pr(>|t|)"]
  
  # Store results in data frame
  results2 <- rbind(
    results2,
    data.frame(
      Portfolio = i,
      Alpha = alpha,
      Beta = beta,
      R2 = r_squared,
      adj_R2 = adj_r_squared,
      StdErrAlpha = std_err_alpha,
      StdErrBeta = std_err_beta,
      PValueAlpha = p_value_alpha,
      PValueBeta = p_value_beta
    )
  )
}

rownames(results2) <- NULL
```
```{r}
sum(results$R2>results2$R2)
sum(results$adj_R2>results2$adj_R2)
```

Looking at the example where we subset the data into three time-periods, we see that all $R^2$ for the model including time-specific intercepts and betas are larger compared to the original CAPM. Looking at the adjusted $R^2$, we see that 95/100 $R^2_{adj.}$ are larger.

This is a clear indication that the inclusion of period-specific effects increases the model's goodness-of-fit.

### (c) Do you find for particular size and book-to-market portfolios stronger time variations in market betas than for other?

```{r, echo=F}
# En lösning, tror det kan vara vettigt?

beta_period1 <- results$Beta
beta_period2 <- beta_period1 + results$InteractionPeriod2Market
beta_period3 <- beta_period1 + results$InteractionPeriod3Market
betas <- cbind(beta_period1, beta_period2, beta_period3)
rownames(betas) <- colnames(excess_returns)[2:101]

# Calculate variance of betas across periods
beta_variation <- apply(betas, 1, var)

# Extract size and book-to-market deciles from portfolio names
portfolio_names <- colnames(excess_returns)[2:101]

# Function to extract size and book-to-market deciles
extract_deciles <- function(name) {
  # Extract size decile
  if (substr(name, 2, 3) == "10") {
    size_decile <- 10  # For size 10 decile
  } else {
    size_decile <- as.numeric(substr(name, 2, 2))  # Otherwise, take the second character
  }
  
  # Extract book-to-market decile
  if (substr(name, 4, 5) == "10" || substr(name, 3, 4) == "10") {
    book_to_market_decile <- 10  # For book-to-market 10 decile
  } else {
      if (is.na(as.numeric(substr(name, 4, 4)))){
        book_to_market_decile <- as.numeric(substr(name, 3, 3))
      } else{
    book_to_market_decile <- as.numeric(substr(name, 4, 4))
        }
    }
                                      
  return(c(size_decile, book_to_market_decile))
}

# Apply function to all portfolio names
deciles <- t(sapply(portfolio_names, extract_deciles))
size_decile <- deciles[, 1]
book_to_market_decile <- deciles[, 2]

# Combine beta variation with size and book-to-market deciles
beta_variation_df <- data.frame(
  Portfolio = portfolio_names,
  Size = as.factor(size_decile),
  BookToMarket = as.factor(book_to_market_decile),
  BetaVariation = beta_variation
)

# Alternatively, create a heatmap
ggplot(beta_variation_df, aes(x = Size, y = BookToMarket, fill = BetaVariation)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "darkblue") +
  labs(title = "Heatmap of Beta Variation by Size and Book-to-Market",
       x = "Size Decile",
       y = "Book-to-Market Decile",
       fill = "Beta Variation") +
  theme_minimal()
```
Above we have plotted the variation in betas between time periods against the Size decile and book-to-market ratios. The pattern we see is that the portfolios consisting of larger size firms seem to have less variation in betas between the time periods. Portfolios with lower book-to-market ratios also have smaller variance in the betas between time periods. 

Based on this plot, it seems that high book-to-market portfolios are most volatile over time as the variation in beta is high for almost all portfolios with high book-to-market. There also seem to be a relationship between size and time variation, however this relationship does not seem to be as strong based on the above plot. In contrast, larger portfolios with low book-to-market is least volatile.

# B. Cross-sectional regressions
Use the data set `portfolio_m` analyzed in the previous section. In the following you have to analyze the cross-sectional implications of the CAPM

## 1. Write R code to implement the First Pass regression which computes the cross-section of market betas, and save them together with the period-specific excess returns. Apply the code to compute the betas for the 100 size-book-to-market portfolios. Using the results to analyze the following issues:

```{r, echo=F}
FirstPass <- function(mZ, vZm){
  iT = nrow(mZ)
  iN = ncol(mZ)
  
  # First Pass
  mX = cbind(1,vZm)
  pars = chol2inv(chol(crossprod(mX)))%*%crossprod(mX,mZ)
  alpha = c(pars[1,])
  # estimated betas
  beta = c(pars[2,])
  # sample mean of each excess return
  mu = apply(mZ,2,mean)
  # sample mean of the market excess return
  mum = mean(vZm)
  # variance of the market excess return
  sigm2 = c(crossprod(vZm-mum))/iT
  # residuals
  me = mZ-mX%*%pars
  # covariance matrix of the residuals
  Sigma = crossprod(me)/iT
  #predicted values
  mZ_hat <- mX%*%pars
  #residuals
  mResiduals <- mZ - mZ_hat
  #vector to store R^2 values for each portfolio
  R2 = numeric(iN)
  
  for (j in 1:iN) {
    # Residual Sum of Squares for portfolio j
    RSS_j = sum(mResiduals[, j]^2)
    # Total Sum of Squares for portfolio j
    TSS_j = sum((mZ[, j] - mean(mZ[, j]))^2)
    # R-squared for portfolio j
    R2[j] = 1 - RSS_j / TSS_j
  }
  return(list(alpha=alpha,beta=beta,R2=R2,mu=mu,mum=mum))
}

mR = as.matrix(portfolio_m[,25:124])
Rf = as.matrix(portfolio_m[,'Tbill'])
Rm = as.matrix(portfolio_m[,'Market'])
mZ = sweep(mR,1,Rf)
vZm = Rm - Rf

fpreg <- FirstPass(mZ, vZm)
```

### (a) Evaluate the cross-sectional distribution of the estimated betas. Test whether the average betas are significantly different from one. Interpret your findings.

First we evaluate the cross-sectional distribution of the estimated betas.

```{r}
descriptive_stats <- describe(fpreg$beta)[,c("mean","median", "sd", "skew", "kurtosis", "min", "max")]
rownames(descriptive_stats) <- "beta"
kable(descriptive_stats, digits = 3)
```

We can see that the mean is 1.171 and median is also 1.171 which means that these portfolios points towards slightly higher systematic risk compared to the market where the expectation of beta would be 1. 
The standard deviation of 0.18 is quite low which is interpreted as that most portfolios are clustered around the mean and therefore would indicate a well diversified portfolio. The distribution seems to be slightly negatively skewed capturing some portfolios who exhibit low betas, i.e. lower risk compared to market. Furthermore, the distribution is quite flat with a kurtosis of 0.422 and showing quite thin tails since most of the data is around the mean. The min and max show the asymmetry and points also towards slightly negative data with a longer lower tail. 

Now lets plot the histogram of the betas and plot the QQ-plot to see these findings visually.
```{r}
hist(fpreg$beta)
lines(density(fpreg$beta), col = "blue", lwd = 2)
abline(v = descriptive_stats$mean, col = "red", lwd = 2, lty = 2)
qqnorm(fpreg$beta)
qqline(fpreg$beta, col = "red")
```
The blue line is the density line for the betas and the red dashed vertical line is the mean. The QQ-plot shows the data compared to a theoretical normal distribution and we can see that the betas are not quite normally distributed. The QQ-plot shows some heavier left tails and also some thinner right tails. The bulk of the data follows a normal distribution quite good but this still points towards that the data is not normally distributed.

Now to test whether the average betas are significantly different from one. Let us divide the data in three equally large periods again, first, middle and last part of the data, and to the test for each period.

```{r}
# Divide data into sub-periods, 314 time-points in each
subsample1 <- 1:314
subsample2 <- 315:628
subsample3 <- 629:942
subsamples <- list(subsample1,subsample2,subsample3)
```

We test on a 5% significance level
$$
\begin{aligned}
H_0:\mu_{\hat{\beta}}=1\\
H_a:\mu_{\hat{\beta}}\neq1
\end{aligned}
$$
So we can use the test statistic

$$
T=\frac{\hat{\mu}_{\hat{\beta}}-1}{\hat{\sigma}_{\hat{\beta}}/\sqrt{n}} \sim t_{n-1}
$$
Note that we do this test under the assumption that the $\hat{\beta}$'s are i.i.d. which may not be very realistic. But still we assume this. Lets implement it in code and do the test for each period

```{r}
means <- numeric(length(subsamples))
tstats <- numeric(length(subsamples))
pvals <- numeric(length(subsamples))
tcheck <- list()

betas_list <- list()

for (i in 1:length(subsamples)){
  mR = as.matrix(portfolio_m[subsamples[[i]],25:124])
  Rf = as.matrix(portfolio_m[subsamples[[i]],'Tbill'])
  Rm = as.matrix(portfolio_m[subsamples[[i]],'Market'])
  mZ = sweep(mR,1,Rf)
  vZm = Rm - Rf

  tmp = FirstPass(mZ, vZm)
  betas <- tmp$beta
  betas_list[[i]] <- betas
  means[i] <- mean(betas)

  Tstat <- (mean(betas)-1)/(sd(betas)/sqrt(length(betas)))
  pval <- 2*pt(abs(Tstat), df=length(betas)-1,lower.tail=FALSE)
  
  tstats[i] <- Tstat
  pvals[i] <- pval
  tcheck[[i]] <- t.test(betas,mu=1)
}

data <- data.frame(
  Metric = c("sample mean", "t-stat", "p-value"),
  Period_1 = c(round(means[1],4), round(tstats[1],4), round(pvals[1],4)),
  Period_2 = c(round(means[2],4), round(tstats[2],4), round(pvals[2],4)),
  Period_3 = c(round(means[3],4), round(tstats[3],4), round(pvals[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "period specific t-test for average beta =1"
)
```

We can see that for period 1 and period 2, we strongly reject the null, i.e. the average beta in both periods is significantly different from one. Although in period 3, the p-value is really high at 0.96, so for period 3 we definitely do not reject the null, so accept the alternative that the average beta in period 3 is 1.

### (b) Evaluate the cross-sectional distribution of the computed (time series) \(R^2\)'s. What can you learn from this analysis?

```{r}
descriptive_stats <- describe(fpreg$R2)[,c("mean", "median", "sd", "skew", "kurtosis", "min", "max")]
rownames(descriptive_stats) <- "R^2"
kable(descriptive_stats, digits = 3)
```

We can see that is quite heavily left skewed. First of all the mean is slightly lower than the median indicating that there are some R^2 on the lower end pulling the mean down and therefore pointing towards a left skewed data. The negative skewness of -0.817 also indicates that the tail on the lower end is longer. The negative kurtosis indicates on a platykurtic distribution where most of the values are around the mean. The standard deviation is quite low but relative to this data it describes a moderate variability for R^2. The lowest value is 0.186 and the highest value is 0.873 which shows a fairly high spread and implies that some of the models have low explanatory power but most of them have a high explanatory power since the majority of the data is around the mean and in the range between 0.6 and 0.8. 

```{r}
hist(fpreg$R2)
lines(density(fpreg$R2), col = "blue", lwd = 2)
abline(v = descriptive_stats$mean, col = "red", lwd = 2, lty = 2)
```
We clearly see the left skewness, i.e. a lot of higher $R^2$ happens to the right, so in essence in most cases the $R^2$ is high/, i.e. the CAPM model captures a lot of variation in the data. These findings indicate that most of the models explain a high proportion of variance in returns for the majority of assets and therefore a good model fit. The negative skewness indicates that some models have poor explanatory power and this can be due to idiosyncratic or sector-specific behavior. Lastly, the thin tails indicate that the models are quite consistent in the explanatory power across the sample and thus is relatively stable.


### (c) Evaluate the relationship between average excess returns and market betas. What would you expect from economic theory and what do you find?

Now the economic theory says that the CAPM implies

$$
E[Z_{it}]=\beta_iE[Z_{mt}]
$$
Now we want to verify to what extent this is correct. We do not have the expectations, so a (not so mathematically rigorous) compromise is to use the averages, and see if it holds, i.e. does the following equation approximately hold?

$$
T^{-1}\sum_{t=1}^TZ_{it}=\beta_iT^{-1}\sum_{t=1}^TZ_{mt}
$$
Set up the equation in the code

```{r}
# sample mean of each excess return
mu <- fpreg$mu
# sample mean of the market excess return
mum <- fpreg$mum
# betas
beta <- fpreg$beta

lhs <- mu # left hand side of equation
rhs <- beta * mum # right hand side of equation
```

Now if we plot a scatterplot with the left hand side against the right hand side against the equation, if it holds perfectly, we should see that all points lie on a 45 degree line, i.e. the economic theory prediction (CAPM) is the 45 degree line. Lets try it

```{r}
library(ggplot2)

# Create a data frame for visualization
data <- data.frame(lhs = lhs, rhs = rhs)

# Scatter plot with a 45-degree reference line
ggplot(data, aes(x = rhs, y = lhs)) +
  geom_point(color = "blue", size = 2) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(
    title = "CAPM Predictions (red line) vs. empirical reality (blue points)",
    x = "Beta * average Market Excess Return",
    y = "Average Portfolio Excess Return"
  ) +
  theme_minimal()
```
We can see that it seems to hold relatively well for some portfolios, but not for others. Some are really really close on the line, so for these portfolios the CAPM prediction from economic theory holds really well.

## 2 Estimate the following cross-sectional model for individual periods t in Second Pass:

$$
Z_t = \gamma_{0t} \iota + \gamma_{1t}\hat{\beta}_m + \eta_t
$$

where $Z_t$ is an $N\times 1$ vector of excess asset returns for time period t, $\iota$ is an $N\times 1$ vector of ones, and $\hat{\beta}_m$ is the $N\tims 1$ vector of pre-estimated CAPM betas.

Lets first set up the Second Pass

```{r}
SecondPass <- function(beta, mZ){
  iT = nrow(mZ)
  iN = ncol(mZ)
  mX = cbind(1,beta)
  xxinv = chol2inv(chol(crossprod(mX)))
  xxinvx = tcrossprod(xxinv,mX)
  gamma = NULL; gamsd = NULL
  for(iter in 1:iT){
    vy = mZ[iter,]
    tmp = xxinvx%*%vy
    # gamma
    gamma = rbind(gamma, c(tmp))
    s2 = c(crossprod(vy - mX%*%tmp))/iN
    # gammas' standard error
    gamsd = rbind(gamsd, sqrt(diag(s2 * xxinv)))
  }
  
  # gamma0 and market risk premia
  gamma0 = c(gamma[,1]); g0sd = c(gamsd[,1])
  mrprem = c(gamma[,2]); prsd = c(gamsd[,2])
  
  # w tests on pp.30 in slides for lecture 4
  # should be compared with student t with T-1 degrees of freedom
  # or with standard normal if T is large
  wgamma0 = mean(gamma0)/sqrt(sum((gamma0-mean(gamma0))**2)/iT/(iT-1))
  wgamma1 = mean(mrprem)/sqrt(sum((mrprem-mean(mrprem))**2)/iT/(iT-1))
  
  return(list(gamma0=gamma0,g0sd=g0sd,mrprem=mrprem,prsd=prsd,wgamma0=wgamma0,wgamma1=wgamma1,iT=iT))
}
```

We again split up the data in the 3 periods, and do the tests for each period, to see how robust the results are over time.
```{r}
# Divide data into sub-periods, 314 time-points in each
subsample1 <- 1:314
subsample2 <- 315:628
subsample3 <- 629:942
subsamples <- list(subsample1,subsample2,subsample3)

pval_wgamma0_v <- numeric(length(subsamples))
wgamma0_v <- numeric(length(subsamples))

pval_wgamma1_v <- numeric(length(subsamples))
wgamma1_v <- numeric(length(subsamples))

Tstat_gamma0_v <- numeric(length(subsamples))
pval_avg_gamma0_v <- numeric(length(subsamples))

Tstat_gamma1_v <- numeric(length(subsamples))
pval_avg_gamma1_v <- numeric(length(subsamples))

vgamma0 <- list()
vgamma1 <- list()

ttestsg0 <- list()
ttestsg1 <- list()

for (i in 1:length(subsamples)){
  mR = as.matrix(portfolio_m[subsamples[[i]],25:124])
  Rf = as.matrix(portfolio_m[subsamples[[i]],'Tbill'])
  Rm = as.matrix(portfolio_m[subsamples[[i]],'Market'])
  mZ = sweep(mR,1,Rf)
  vZm = Rm - Rf
  
  FPreg <- FirstPass(mZ, vZm)
  SPreg <- SecondPass(FPreg$beta, mZ)
  
  gamma1test[[i]] <- SPreg$mrprem
  iT <- SPreg$iT
  
  # a)
  wgamma0 <- SPreg$wgamma0
  pval_wgamma0_v[i] <- 2*pt(abs(wgamma0), df=iT-1,lower.tail=FALSE)
  wgamma0_v[i] <- wgamma0
  # b)
  wgamma1 <- SPreg$wgamma1
  pval_wgamma1_v[i] <- pt(wgamma1, df=iT-1, lower.tail=FALSE)
  wgamma1_v[i] <- wgamma1
  # c) 1. gamma0
  gamma0 <- SPreg$gamma0
  Tstat <- (mean(gamma0)-0)/(sd(gamma0)/sqrt(length(gamma0)))
  Tstat_gamma0_v[i] <- Tstat
  pval_avg_gamma0_v[i] <- 2*pt(abs(Tstat), df=length(gamma0)-1,lower.tail=FALSE)
  ttestsg0[[i]] <- t.test(gamma0, alternative=c("two.sided"),mu=0)
  vgamma0[[i]] <- gamma0
  # c) 2. gamma1
  gamma1 <- SPreg$mrprem
  Tstat <- (mean(gamma1)-0)/(sd(gamma1)/sqrt(length(gamma1)))
  Tstat_gamma1_v[i] <- Tstat
  pval_avg_gamma1_v[i] <- pt(wgamma1, df=iT-1, lower.tail=FALSE)
  ttestsg1[[i]] <- t.test(gamma1, alternative=c("greater"),mu=0)
  vgamma1[[i]] <- gamma1
}
```

### (a) Test whether \(\gamma_{0t}=0\) for all t

This is a two tailed t-test.

```{r}
data <- data.frame(
  Metric = c("wgamma0", "p-value"),
  Period_1 = c(round(wgamma0_v[1],4), round(pval_wgamma0_v[1],4)),
  Period_2 = c(round(wgamma0_v[2],4), round(pval_wgamma0_v[2],4)),
  Period_3 = c(round(wgamma0_v[3],4), round(pval_wgamma0_v[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "Test for gamma_0t=0"
)
```

Our p-value is 0.79 so we do not reject the null that $\gamma_{0t}=0$ for all t.

### (b) Test whether \(\gamma_{1t}>0\) for all t

Now we actually test the null in the other direction $\gamma_{1t}\le0$ because then we get the alternative that is strictly larger, i.e. $\gamma_{1t}>0$

```{r}
data <- data.frame(
  Metric = c("wgamma1", "p-value"),
  Period_1 = c(round(wgamma1_v[1],4), round(pval_wgamma1_v[1],4)),
  Period_2 = c(round(wgamma1_v[2],4), round(pval_wgamma1_v[2],4)),
  Period_3 = c(round(wgamma1_v[3],4), round(pval_wgamma1_v[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "Test for gamma_1t>0 (H_0:gamma_1t<=0)"
)
```

We can see that for period 1, we reject the null of $\gamma_{1t}\le0$ for all t at a 5% significance level, so we accept the alternative of $\gamma_{1t}>0$. For period 2 and 3, we accept the null that the market risk premia is less than or equal to zero $\gamma_{1t}\le0$ actually.

### (c) Test whether \(\bar{\gamma}_1 = T^{-1}\sum_{t=1}^T \hat{\gamma}_{1t} > 0\) and \(\bar{\gamma}_0 = T^{-1}\sum_{t=1}^T \hat{\gamma}_{0t} = 0\)

First we test $\bar{\gamma}_0 = T^{-1}\sum_{t=1}^T \hat{\gamma}_{0t} = 0$.
```{r}
data <- data.frame(
  Metric = c("sample mean", "t-stat", "p-value"),
  Period_1 = c(round(mean(vgamma0[[1]]),4), round(Tstat_gamma0_v[1],4), round(pval_avg_gamma0_v[1],4)),
  Period_2 = c(round(mean(vgamma0[[2]]),4), round(Tstat_gamma0_v[2],4), round(pval_avg_gamma0_v[2],4)),
  Period_3 = c(round(mean(vgamma0[[3]]),4), round(Tstat_gamma0_v[3],4), round(pval_avg_gamma0_v[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "Test for gamma_0t=0"
)
```
Now we test $\bar{\gamma}_1 = T^{-1}\sum_{t=1}^T \hat{\gamma}_{1t} > 0$.
```{r}
data <- data.frame(
  Metric = c("sample mean", "t-stat", "p-value"),
  Period_1 = c(round(mean(vgamma1[[1]]),4), round(Tstat_gamma1_v[1],4), round(pval_avg_gamma1_v[1],4)),
  Period_2 = c(round(mean(vgamma1[[2]]),4), round(Tstat_gamma1_v[2],4), round(pval_avg_gamma1_v[2],4)),
  Period_3 = c(round(mean(vgamma1[[3]]),4), round(Tstat_gamma1_v[3],4), round(pval_avg_gamma1_v[3],4))
)

kable(
  data,
  col.names = c("", "Period 1", "Period 2", "Period 3"),
  caption = "Test for gamma_1t>0 (H_0:gamma_1t<=0)"
)
```
We assume the gammas are i.d.d. This is a strong assumption and not realistic. But still, if we assume, we can do it.

theory says we should reject gamma1t is zero, rule out case where it is negative.

It is exactly the same test statistics and p-values...

and evaluate the goodness-of-fit. How robust are your results over time?

## 3. Generate two variables indicating the corresponding underlying size and book-to-market decile for each portfolio over the cross-section.


### (a) Plot the corresponding size and book-to-market decile numbers against the average returns of the corresponding portfolios. What do you find? Do you expect that size and book-to-market effects have explanatory power in the cross-sectional equation (1)?

We start by generating two factor variables for size and book-to-market which we will use to plot the average returns.

```{r}
mR = as.matrix(portfolio_m[,25:124])
Rf = as.matrix(portfolio_m[,'Tbill'])
Rm = as.matrix(portfolio_m[,'Market'])
mZ = sweep(mR,1,Rf)
vZm = Rm - Rf
  
reg <- FamaMacbeth0(mZ, vZm)

avg_ret <- mean(reg$gamma0) + mean(reg$mrprem)%*%(reg$beta)
avg_ret_df <- data.frame(
  Size = as.factor(size_decile),
  BookToMarket = as.factor(book_to_market_decile),
  avg_ret = t(avg_ret)
)
```

### (a) Plot the corresponding size and book-to-market decile numbers against the average returns of the corresponding portfolios. What do you find? Do you expect that size and book-to-market effects have explanatory power in the cross-sectional equation (1)?

```{r}
ggplot(avg_ret_df, aes(x = Size, y = BookToMarket, fill = avg_ret)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "darkblue") +
  labs(title = "Heatmap of Average Returns by Size and Book-to-Market",
       x = "Size Decile",
       y = "Book-to-Market Decile",
       fill = "Average Returns") +
  theme_minimal()
```
In the figure above we have plotted a heat map of average returns against size and book to market. What we see is that smaller size and larger book-to-market generally have higher average returns compared to portfolios of larger size and lower book to market. This pattern is quite clear but we do see some exceptions, for example R13 and R14 which are of small size but still have quite low returns, similarly R1010 has low returns even though the book-to-market is high. The size and book-to-market ratio seem to affect the average returns but does not seem to explain all of the variation.

Based on this we believe that size and book-to-market effects will have explanatory power in the cross-sectional equation (1).


### (b) Augment equation (1) by these two variables and analyze whether they have explanatory power beyond the CAPM betas. Interpret your findings.

For this task we will log transform the size and book-to-market deciles:


$$
Z_t = \gamma_{0t} \iota + \gamma_{1t}\hat{\beta}_m + + \gamma_{2t}log(Size)+\gamma_{3t}log(BtM) + \eta_t
$$

We use the log transformed deciles for two reasons: The exercise states that we should generate \textbf{two} variables indicating the corresponding underlying size and book-to-market decile for each portfolio over the cross-section. This rules out using the constructed factors as is since this would require us to generate 18 dummy variables. The next reason is that we can not employ the variables as continuous as this would imply a linear relationship between the deciles and returns which is likely not true. It is more likely that there is a diminishing effect of size and book-to-market on returns, i.e. moving from size decile 1 to 2 might have a greater impact on returns compared to decile 9-10, and similarly for book-to-market. 

Both of these problems are solved by using log transformed deciles rather than dummy variables.

```{r}

```







```{r, include=F}
### Spar denna liten stund
### Alternativ model för A3, jag föredrar dock den med dummies/Erik

extended_CAPM <- function(y1, x1, y2, x2, y3, x3) {
  # Fit models
  full_sample_fit <- lm(c(y1, y2, y3) ~ c(x1, x2, x3))
  group_1_fit <- lm(y1 ~ x1)
  group_2_fit <- lm(y2 ~ x2)
  group_3_fit <- lm(y3 ~ x3)
  
  results <- list(
    full_sample = full_sample_fit,
    period_1 = group_1_fit,
    period_2 = group_2_fit,
    period_3 = group_3_fit
  )
  
  return(results)
}


# Divide data into time periods
t1 <- 1:314
t2 <- 315:628
t3 <- 629:942

# Market excess returns
ER_M <- as.matrix(portfolio_m[, 3] - portfolio_m$Tbill)
x1 <- ER_M[t1]
x2 <- ER_M[t2]
x3 <- ER_M[t3]

# Initialize data frames for results
results <- data.frame(
  Portfolio = integer(),
  Alpha = numeric(),
  Beta = numeric(),
  R2 = numeric(),
  AdjR2 = numeric(),
  StdErrAlpha = numeric(),
  StdErrBeta = numeric(),
  PValueAlpha = numeric(),
  PValueBeta = numeric()
)

results_extended <- data.frame(
  Portfolio = integer(),
  Period = character(),
  Alpha = numeric(),
  Beta = numeric(),
  R2 = numeric(),
  AdjR2 = numeric(),
  StdErrAlpha = numeric(),
  StdErrBeta = numeric(),
  PValueAlpha = numeric(),
  PValueBeta = numeric()
)

# Loop through portfolios
for (i in 25:124) {
  # Portfolio excess returns
  ER <- as.matrix(portfolio_m[, i] - portfolio_m$Tbill)
  y1 <- ER[t1]
  y2 <- ER[t2]
  y3 <- ER[t3]
  
  # Run the CAPM
  capm_results <- extended_CAPM(y1, x1, y2, x2, y3, x3)
  
  # Extract results for the full sample
  full_sample_summary <- capm_results[["full_sample"]]
  results <- rbind(
    results,
    data.frame(
      Portfolio = i,
      Alpha = coef(full_sample_summary)[1],  # Intercept
      Beta = coef(full_sample_summary)[2],   # Slope
      R2 = summary(full_sample_summary)$r.squared,
      AdjR2 = summary(full_sample_summary)$adj.r.squared,
      StdErrAlpha = coef(summary(full_sample_summary))[1, 2],
      StdErrBeta = coef(summary(full_sample_summary))[2, 2],
      PValueAlpha = coef(summary(full_sample_summary))[1, 4],
      PValueBeta = coef(summary(full_sample_summary))[2, 4]
    )
  )
  
  # Extract results for sub-periods
  for (period in c("period_1", "period_2", "period_3")) {
    period_summary <- capm_results[[period]]
    results_extended <- rbind(
      results_extended,
      data.frame(
        Portfolio = i,
        Period = period,
        Alpha = coef(period_summary)[1],  # Intercept
        Beta = coef(period_summary)[2],   # Slope
        R2 = summary(period_summary)$r.squared,
        AdjR2 = summary(period_summary)$adj.r.squared,
        StdErrAlpha = coef(summary(period_summary))[1, 2],
        StdErrBeta = coef(summary(period_summary))[2, 2],
        PValueAlpha = coef(summary(period_summary))[1, 4],
        PValueBeta = coef(summary(period_summary))[2, 4]
      )
    )
  }
}
rownames(results) <- NULL
rownames(results_extended) <- NULL
```

asda

```{r}
mR = as.matrix(portfolio_m[,25:124])
Rf = as.matrix(portfolio_m[,'Tbill'])
Rm = as.matrix(portfolio_m[,'Market'])
mZ = sweep(mR,1,Rf)

vZm = Rm - Rf

FPreg <- FirstPass(mZ, vZm)
spreg <- SecondPass(FPreg$beta, mZ)
gamma0 <- spreg$gamma0

iT <- spreg$iT
(wgamma0 <- spreg$wgamma0)
(pval <- 2*pt(abs(wgamma0), df=iT-1,lower.tail=FALSE))
```