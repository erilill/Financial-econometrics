---
title: "Report for PS 2"
author:
- Mark Becker, Erik Lillrank & Vilim Nedic
date: ''
output:
  pdf_document:
    keep_tex: true
  df_print: kable
  html_document:
    df_print: paged
  word_document: default
header-includes:
  - \usepackage{float}
  - \usepackage{booktabs}
  - \usepackage{multirow}
  - \usepackage{caption}
  - \usepackage{subcaption}
  - \usepackage{adjustbox}
toc: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(FE)
library(knitr)
library(forecast)
library(patchwork)
library(kableExtra)
library(dplyr)
library(purrr)
data("DJ_w")
data("DJ_d")
data("portcap_m")
```

# A. Testing for asset return predicatability.
Use the data sets ”DJ_d” (Dow Jones daily) and ”DJ_w” (Dow Jones weekly) containing daily and weekly observations of the Dow Jones index. In the following, you have to test for asset return predictability based on autocorrelation functions, Ljung-Box statistics as well as variance ratio tests.

## 1. Do you find significant evidence for asset return predictability on the daily and weekly level?

For this question, we will use autocorrelation functions, Lung-Box statistics and variance ratio tests in order to gage whether there is significant evidence for asset return predictability.

ACF: 
```{r A1_ACF, echo=F}
par(mfrow=c(1,2))
p1 <- Acf(DJ_d$r_Dow_Jones, lag.max = 20, main = "Dow Jones daily")
p2 <- Acf(DJ_w$r_close, lag.max = 20, main = "Dow Jones weekly")
par(mfrow=c(1,1))
```
Above you see the ACF plots for the Dow Jones daily and weekly data with 20 lags. For easier interpretation, lag 0 has been omitted.

What we see from the plots is that we have large spikes for the first two lags in the daily data, with some moderately large spikes for further lags. For the weekly data we essentially only see 2 barely significant spikes. This is a quite strong indication of asset return predictability on the daily level, and a for the weekly level it is an indication that there may be some asset predictability, but not very much. At least we need to investigate further, as it is not as clear like for the daily data.


Ljung-Box test:

```{r A1_LB, include=F}
LB <- function(vx,lag,ip){
  tmp = acf(vx,lag.max=lag,plot=F)$acf
  tmp = tmp[2:(lag+1)]**2
  test = sum(tmp/(length(vx)-1:lag))*length(vx)*(length(vx)+2)
  return(list(test=test, pval=1-pchisq(test,df=lag-ip)))
}

gridsearch <- function(data, lag){
  results <- matrix(NA, nrow=length(lag), ncol = 2)
  for (j in 1:length(lag)){
      lagj <- lag[j]
      results[j,1]<-LB(vx=data,lag=lagj,ip=0)$test
      results[j,2]<-LB(vx=data,lag=lagj,ip=0)$pval
    }
  return(results)
}
lag = c(5,10,20)
t1 <- gridsearch(DJ_d$r_Dow_Jones, lag)
t2 <- gridsearch(DJ_w$r_close, lag)
cbind(t1,t2)
```
\begin{table}[ht]
\centering
\caption{Ljung-Box Test Statistics for Dow Jones Daily and Weekly Returns (Rounded to 3 Decimal Places)}
\label{tab1:LB}
\begin{tabular}{lcccc}
\toprule
\multirow{2}{*}{Lag} & \multicolumn{2}{c}{Dow Jones Daily} & \multicolumn{2}{c}{Dow Jones Weekly} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
 & $Q_{LB}$ & p-value & $Q_{LB}$ & p-value \\ 
\midrule
5  & 329.899 & 0.000 & 5.144 & 0.399 \\ 
10  & 371.600 & 0.000 & 13.592 & 0.192 \\ 
20  & 388.925 & 0.000 & 23.320 & 0.273 \\ 
\bottomrule
\end{tabular}
\end{table}

So we now test the nulls that the first 5, 10 and 20 autocorrelations are all zero. We see from table \ref{tab1:LB} that the p-values for 5, 10, and 20 lags are zero ($<\alpha=0.01$) for the daily data, meaning that we have significant auto-correlations at the 1% level. This is quite strong evidence for asset return predictability in the daily data. For the weekly series, all p-values are above $\alpha=0.1$, so we can not even reject at the 10% level. So for weekly data we do not reject the nulls that the first 5, 10 and 20 autocorrelations are all zero, indicating that there is no prevalence of asset return predictability for the weekly level. 

Variance ratio test:

```{r A1_VR, include=F}
VDR <- function(vr,iq){
  iTT = length(vr)
  im = floor(iTT/iq)
  iT = im*iq
  
  rr = vr[1:iT]
  mu = mean(rr)
  sa2 = var(rr)
  
  arr = NULL
  for(iter in 1:(iT-iq+1))
    arr = c(arr,sum(rr[iter:(iter+iq-1)]))
  
  sc2 = sum((arr-mu*iq)**2)/iq/(iT-iq+1)/(1-(1/im))
  
  VD = sc2 - sa2
  VR = sc2/sa2
  tmp = sqrt(2*(2*iq-1)*(iq-1)/3/iq)
  
  VD = VD*sqrt(iT)/sa2/tmp
  VR = (VR-1)*sqrt(iT)/tmp
  
  RW1_p_VD <- 2*(1-pnorm(abs(VD)))
  RW1_p_VR <- 2*(1-pnorm(abs(VR)))
  
  return(list(VD=VD, VR=VR, RW1_p_VD=RW1_p_VD, RW1_p_VR=RW1_p_VR))
}
q <- c(2,4,8,16)
res_d <- matrix(NA, nrow=4, ncol=4)
res_w <- matrix(NA, nrow=4, ncol=4)

for (i in 1:length(q)){
res_1 <- VDR(vr=DJ_d$r_Dow_Jones,iq=q[i])
res_2 <- VDR(vr=DJ_w$r_close,iq=q[i])
res_d[i,1] <- res_1$VD
res_d[i,2] <- res_1$RW1_p_VD
res_d[i,3] <- res_1$VR
res_d[i,4] <- res_1$RW1_p_VR
res_w[i,1] <- res_2$VD
res_w[i,2] <- res_2$RW1_p_VD
res_w[i,3] <- res_2$VR
res_w[i,4] <- res_2$RW1_p_VR
}
cbind(round(res_d,3),round(res_w,3))
```
\begin{table}[ht]
\centering
\caption{The variance ratio test under RW1. Presented are variance distance, ratio, and p-values for Dow Jones daily and weekly data.}
\label{tab:VDR1}
\begin{tabular}{c|cccc|cccc}
\hline
\multicolumn{1}{c|}{} &
\multicolumn{4}{c|}{Dow Jones Daily} & \multicolumn{4}{c}{Dow Jones Weekly} \\ \hline
q & VD & p-value & VR & p-value & VD & p-value & VR & p-value \\ \hline
2 & 13.402 & 0.000 & 13.402 & 0.000 & -0.936 & 0.349 & -0.936 & 0.349 \\
4 & 5.642 & 0.000 & 5.642 & 0.000 & -0.489 & 0.625 & -0.489 & 0.625 \\
8 & 5.410 & 0.000 & 5.410 & 0.000 & 0.197 & 0.844 & 0.197 & 0.844 \\
16 & 5.359 & 0.000 & 5.359 & 0.000 & 0.574 & 0.566 & 0.574 & 0.566 \\
\hline
\end{tabular}
\end{table}

We now test the null of Random Walk returns, i.e. no predictability. The p-values are zero for all $q$, indicating that we have strong (significant at 1% level) evidence for asset return predictability for daily data. For the weekly series, looking at the p-values we see that the results are not statistically significant at even the 10% level, and we can therefore not reject the null. As such, we do not have evidence of asset return predictability for the weekly data.

## 2. What about the asset return predictability of two-day and two-week returns? What about the higher aggregated returns?

We create the annualized two-day and two-week returns like below.

```{r, echo=T}
oneday <- DJ_d$r_Dow_Jones
oneday <- oneday[-1] # remove first obs, otherwise below doesn't work
oneweek <- DJ_w$r_close

twoday <- oneday[seq(1, length(oneday), by = 2)] + oneday[seq(2, length(oneday), by = 2)]
twoday_ann <- twoday/2 #to make it annualized

twoweek <- oneweek[seq(1, length(oneweek), by = 2)] + oneweek[seq(2, length(oneweek), by = 2)]
twoweek_ann <- twoweek/2 #to make it annualized
```


```{r, echo=F}
par(mfrow=c(1,2))
ts.plot(twoday_ann)
ts.plot(twoweek_ann)
par(mfrow=c(1,1))

par(mfrow=c(1,2))
p3 <- Acf(twoday_ann, lag.max = 20, main = "DJ two day ann. log returns")
p4 <- Acf(twoweek_ann, lag.max = 20, main = "DJ two-week ann. log returns")
par(mfrow=c(1,1))
```

Above we can see ACF plots for the annualized two-day and two-week log returns with 20 lags. For easier interpretation, lag 0 has been omitted.

What we see from the first ACF plot for the two-day is that we have large significant spikes at lag 2 and 4, 11, 15 and 17. For the two-week data we see two significant spikes at 12 and 15, but they are not very large.

So for two-day we see significant auto-correlations for many lags, and quite far out also, this is an indication of asset return predictability. For two-week we see significant auto-correlations for two lags quite far out, this is also an indication of asset return predictability. It is kind of the same conclusion as before, for the two-daily there is strong signs of asset return predictability, for the two-week level we get an indication that there may be some asset predictability, but not very much.

Lets do Ljung Box tests to investigate further.
```{r, include=F}
LB(twoday_ann, lag=20, ip=0)

LB(twoweek_ann, lag=20, ip=0)
```
\begin{table}[ht]
\centering
\caption{Ljung-Box Test Results for Two-Day and Two-week Aggregated Series}
\begin{tabular}{lccl}
\hline
\textbf{Data} & \textbf{Lags} & \textbf{Test Statistic} & \textbf{p-value} \\
\hline
two-day & 20   & 110.17  & 0.00\\
two-week & 20   & 21.54 & 0.37\\
\hline
\end{tabular}
\label{tab:lb_twoday}
\end{table}


So the result tells us that for the two-day returns, that we strongly reject at the 1% level $(\alpha=0.01)$ the null of the first 20 autocorrelations being all zero. For the two-week returns, we can not reject even at the 10% level the null of the first 20 autocorrelations being zero. These results strongly indicate that there is prevalence of asset return predictability for both two-day returns but not for two-week returns.

Variance ratio test:

```{r, include=F}
VDR <- function(vr,iq){
  iTT = length(vr)
  im = floor(iTT/iq)
  iT = im*iq
  
  rr = vr[1:iT]
  mu = mean(rr)
  sa2 = var(rr)
  
  arr = NULL
  for(iter in 1:(iT-iq+1))
    arr = c(arr,sum(rr[iter:(iter+iq-1)]))
  
  sc2 = sum((arr-mu*iq)**2)/iq/(iT-iq+1)/(1-(1/im))
  
  VD = sc2 - sa2
  VR = sc2/sa2
  tmp = sqrt(2*(2*iq-1)*(iq-1)/3/iq)
  
  VD = VD*sqrt(iT)/sa2/tmp
  VR = (VR-1)*sqrt(iT)/tmp
  
  RW1_p_VD <- 2*(1-pnorm(abs(VD)))
  RW1_p_VR <- 2*(1-pnorm(abs(VR)))
  
  return(list(VD=VD, VR=VR, RW1_p_VD=RW1_p_VD, RW1_p_VR=RW1_p_VR))
}

q <- c(2,4,8,16)
res_d <- matrix(NA, nrow=4, ncol=4)
res_w <- matrix(NA, nrow=4, ncol=4)

for (i in 1:length(q)){
res_1 <- VDR(vr=twoday_ann,iq=q[i])
res_2 <- VDR(vr=twoweek_ann,iq=q[i])
res_d[i,1] <- res_1$VD
res_d[i,2] <- res_1$RW1_p_VD
res_d[i,3] <- res_1$VR
res_d[i,4] <- res_1$RW1_p_VR
res_w[i,1] <- res_2$VD
res_w[i,2] <- res_2$RW1_p_VD
res_w[i,3] <- res_2$VR
res_w[i,4] <- res_2$RW1_p_VR
}
cbind(round(res_d,3),round(res_w,3))
```
\begin{table}[ht]
\centering
\caption{The variance ratio test under RW1. Presented are variance distance, ratio, and p-values for Dow jones two-day and two-week (annualized) log returns}
\label{tab:VDR2}
\begin{tabular}{c|cccc|cccc}
\hline
\multicolumn{1}{c|}{} &
\multicolumn{4}{c|}{Two-day} & \multicolumn{4}{c}{Two-week} \\ \hline
q & VD & p-value & VR & p-value & VD & p-value & VR & p-value \\ \hline
2 & -0.880 & 0.379 & -0.880 & 0.379 & -0.603 & 0.546 & -0.603 & 0.546 \\
4 & 2.068 & 0.039 & 2.068 & 0.039 & 0.324 & 0.746 & 0.324 & 0.746 \\
8 & 3.355 & 0.001 & 3.355 & 0.001 & 0.662 & 0.508 & 0.662 & 0.508 \\
16 & 3.070 & 0.002 & 3.070 & 0.002 & 1.487 & 0.137 & 1.487 & 0.137 \\
\hline
\end{tabular}
\end{table}

For the two-day series, the p-values are <0.05 for all $q$ except $q=2$, indicating that we have some evidence for asset return predictability for the two-day returns. For the two-week series, looking at the p-values we see that the results are not statistically significant at even the 10% level, and we can therefore not reject the null. As such, we do not have evidence of asset return predictability for the two-week data.



## 3. Divide the sample into appropriate sub-periods and analyze whether you find evidence of an increasing market efficiency over time.

```{r}
# Dividing the data set into three equally sized time windows 
djd_s1 <- DJ_d[1:6280, ]
djd_s2 <- DJ_d[6281:12560, ]
djd_s3 <- DJ_d[12561:18839, ]
djw_s1 <- DJ_w[1:1562, ]
djw_s2 <- DJ_w[1563:3124, ]
djw_s3 <- DJ_w[3125:4686, ]
```

```{r, echo=F}
par(mfrow=c(1,3))

Acf(djd_s1[, 3], lag.max = 20, main = paste("ACF for DJ_d period 1"), ylim = c(-0.25, 0.25))
Acf(djd_s2[, 3], lag.max = 20, main = paste("ACF for DJ_d period 2"), ylim = c(-0.25, 0.25))
Acf(djd_s3[, 3], lag.max = 20, main = paste("ACF for DJ_d period 3"), ylim = c(-0.25, 0.25))

Acf(djw_s1[, 5], lag.max = 20, main = paste("ACF for DJ_w period 1"), ylim = c(-0.25, 0.25))
Acf(djw_s2[, 5], lag.max = 20, main = paste("ACF for DJ_w period 2"), ylim = c(-0.25, 0.25))
Acf(djw_s3[, 5], lag.max = 20, main = paste("ACF for DJ_w period 3"), ylim = c(-0.25, 0.25))
par(mfrow=c(1,1))
```

Even after dividing into sub-periods, it is kind of the same story as before. The ACF plot tell us that in all periods there is quite strong evidence for predictability for the daily data, and some but not overwhelming evidence for weekly data. Although now the weekly data has larger spikes, so now it may be that after dividing up into periods, we see more evidence for prectability on the weekly level.
```{r, include=FALSE, results='hide'}
Box.test(djd_s1[, 3], lag = 20, type = c("Ljung-Box"))
Box.test(djd_s2[, 3], lag = 20, type = c("Ljung-Box"))
Box.test(djd_s3[, 3], lag = 20, type = c("Ljung-Box"))

Box.test(djw_s1[, 5], lag = 20, type = c("Ljung-Box"))
Box.test(djw_s2[, 5], lag = 20, type = c("Ljung-Box"))
Box.test(djw_s3[, 5], lag = 20, type = c("Ljung-Box"))
```
\begin{table}[ht]
\centering
\caption{Ljung-Box Test Results for daily and weekly data in each period}
\begin{tabular}{lccl}
\hline
\textbf{Data} & \textbf{Lags} & \textbf{Test Statistic} & \textbf{p-value} \\
\hline
daily period 1 & 20   & 133.21  & 0.00\\
daily period 2 & 20   & 265.93 & 0.00\\
daily period 3 & 20   & 212.22 & 0.00\\
weekly period 1 & 20   & 31.383 & 0.05\\
weekly period 2 & 20   & 41.694 & 0.00\\
weekly period 3 & 20   & 32.508 & 0.04\\
\hline
\end{tabular}
\end{table}


The Box-Ljung test although now paint a different picture. At least for daily, it is like before, we reject the nulls and there is strong evidence for market predictability in all periods. But for weekly, we know see that in period 2 and 3 we can reject the null on a 5% level, and in period 1 we can reject on a 10% level. So for each period, we see evidence for predictability for weekly data, which we did not see before.

We pursue to examine the non-overlapping 2 day and 2 weeks paired datasets. 

```{r,results='hide'}
length(twoday_ann) / 3 # 3140
length(twoweek_ann) / 3 # 781

dj_2d_p1 <- twoday_ann[1:3140]
dj_2d_p2 <- twoday_ann[3141:6280]
dj_2d_p3 <- twoday_ann[6281:9419]
dj_2w_p1 <- twoweek_ann[1:781]
dj_2w_p2 <- twoweek_ann[782:1562]
dj_2w_p3 <- twoweek_ann[1563:2343]
```

```{r, echo=F}
par(mfrow=c(1,3))
Acf(dj_2d_p1, lag.max = 20, main = paste("ACF for DJ_d 2-day period 1"), ylim = c(-0.15, 0.15))
Acf(dj_2d_p2, lag.max = 20, main = paste("ACF for DJ_d 2-day period 2"), ylim = c(-0.15, 0.15))
Acf(dj_2d_p3, lag.max = 20, main = paste("ACF for DJ_d 2-day period 3"), ylim = c(-0.15, 0.15))

Acf(dj_2w_p1, lag.max = 20, main = paste("ACF for DJ_w 2-week period 1"), ylim = c(-0.15, 0.15))
Acf(dj_2w_p2, lag.max = 20, main = paste("ACF for DJ_w 2-week period 2"), ylim = c(-0.15, 0.15))
Acf(dj_2w_p3, lag.max = 20, main = paste("ACF for DJ_w 2-week period 3"), ylim = c(-0.15, 0.15))
par(mfrow=c(1,1))
```
Again, the ACF plots tell a similar story. For two-day data, we definitely see evidence of market predictability and for two-week data we see some evidence of market predictability, but not as much as for daily.

```{r, include=FALSE, results='hide'}
Box.test(dj_2d_p1, lag = 20, type = c("Ljung-Box"))
Box.test(dj_2d_p2, lag = 20, type = c("Ljung-Box"))
Box.test(dj_2d_p3, lag = 20, type = c("Ljung-Box"))

Box.test(dj_2w_p1, lag = 20, type = c("Ljung-Box"))
Box.test(dj_2w_p2, lag = 20, type = c("Ljung-Box"))
Box.test(dj_2w_p3, lag = 20, type = c("Ljung-Box"))
```
\begin{table}[ht]
\centering
\caption{Ljung-Box Test Results for two-day and two-week data in each period}
\begin{tabular}{lccl}
\hline
\textbf{Data} & \textbf{Lags} & \textbf{Test Statistic} & \textbf{p-value} \\
\hline
two-day period 1 & 20   & 86.233  & 0.0000\\
two-day period 2 & 20   & 28.431 & 0.0996\\
two-day period 3 & 20   & 38.645 & 0.0074\\
two-week period 1 & 20   & 16.632 & 0.6768\\
two-week period 2 & 20   & 35.863 & 0.0160\\
two-week period 3 & 20   & 23.075 & 0.2851\\
\hline
\end{tabular}
\end{table}

For two-day data, we reject on the 1% level in period 1 and 3, but only on the 10% level in period 2. Still, this is kind of the same story as before, we do see evidence for predictability for two-day data. But on the other hand for two-week data, we can not reject on even the 10% level for period 1 and 3, although we can reject on the 5% level for period 2. So we see now evidence for predictability for two-week data, at least in period 2, which we did not see before.

Summarizing, the results are, for one day and two day data, even if we split it up in different time periods, we see evidence of market predictability. So we do not really find increasing market efficiency over time when it comes to one day and two-day data, for the simple fact that we see evidence for predictability in all periods for one-day and two-day data, which implies market inefficiency. For weekly data, for one-week we see more evidence of market predictability in all sub-periods, for two-week data we see more predictability at least in period 2. So you could say that the market was more efficient in period 1 and period 3, in regards to two-week data. And for one-week data the market can be seen as more inefficient when looking at the subperiods rather than the whole period ,because the subperiods indicate predictability while the whole period does not.


## Draw overall conclusions regarding asset return predictability based on this analysis.
Firstly, in question 1 we could see evidence for asset return predictability in daily data but not in weekly data. The ACF plots had many significant spikes for daily data and two barely significant spikes for weekly data. These findings are confirmed by Ljung-Box test where we rejected the null for daily data but not for weekly data, i.e. daily showed predictability while weekly did not. Also the VR/VD was significant for daily but not for weekly, same conclusion.

Secondly, we analyzed the aggregated returns which were very similar to the findings in question 1. We saw some evidence in the ACF plots for two-day data and some evidence but not as strong for two-week data. The Ljung-Box test confirmed these findings, where we rejected the null for the two-day data but not for the two-week data, saying that asset return predictability was prevelent for two-day data but not for two-week. In the VR/VD test, the test statistics were significant for all periods except for when q = 2. For weekly not one test was significant. So again, evidence for predictability was found for two-day but not for two-week.

In question 3, we saw some different results. For daily data however, even if we split up the data into periods, both one-day and two-day showed evidence for market predictability. But for one-week data we now saw evidence for predictability. For two-week, we only saw for period 2.

Given all these findings, we can conclude that asset return predictability is definitely present for daily data, even if it is aggregated. For weekly data, we see some evidence for predictability for one-week and two-week if we split up the data in subsamples, but if we do not split up the data, neither one-week or two-week data show evidence for predictability.

# B. Testing for Return Predictability in Size Portfolios
Use the data set ”portcap_m” containing monthly returns of different U.S. stock portfolios built based on market capitalization. Using (cross-)autocorrelation functions, Ljung-Box statistics as well as variance ratio tests based on the complete time series as well as appropriate sub-periods you have to investigate the following issues

## 1. Is there a relationship between market capitalization and asset return predictability and does it also hold for higher aggregated returns?

We start by inspecting the data.
```{r}
portcap_m
```
We chose to analyze the top and low 10\%, however e.g. top and low 30\% would also be an appropriate choice. We divide the returns by 100 as they are in percentages in the original data. 

```{r}
lo10 <- portcap_m$Lo_10 / 100 
hi10 <- portcap_m$Hi_10 / 100 
```

We will assume that the data contains log returns, this is not clear based on the description but when plotting (simple `ts.plot()`) we see that the returns are centered around zero which is indicative of log returns.

```{r B1_ACF, echo=F}
par(mfrow=c(1,2))
p1 <- Acf(lo10, lag.max = 12, main = "Portfolio returns for low 10%")
p2 <- Acf(hi10, lag.max = 12, main = "Portfolio returns for top 10%.")
par(mfrow=c(1,1))
```
Looking at the ACF-plots above we see significant auto-correlations for both the low and top 10\%, this indicates asset return predictability.

```{r, include=F}
lagss <- c(6,12)
results <- matrix(NA, nrow = length(lagss), ncol = 4)
for(i in 1:length(lagss)){
lb1 <- LB(lo10,lag=lagss[i],ip=0)
lb2 <- LB(hi10,lag=lagss[i],ip=0)
results[i, 1] <- lb1$test
results[i, 2] <- lb1$pval
results[i, 3] <- lb2$test
results[i, 4] <- lb2$pval
}
round(results, 3)
```
\begin{table}[ht]
\centering
\caption{Ljung-Box Test Results for Portfolio returns for low and top 10\% with lag 6 and 12.}
\label{tab:LB_test}
\begin{tabular}{lcccc}
\toprule
\multirow{2}{*}{Lag} & \multicolumn{2}{c}{Low 10\%} & \multicolumn{2}{c}{Top 10\%} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
 & $Q_{LB}$ & p-value & $Q_{LB}$ & p-value \\ 
\midrule
6  & 58.034 & 0.000 & 23.452 & 0.001 \\ 
12  & 83.855 & 0.000 & 31.439  & 0.002 \\ 
\bottomrule
\end{tabular}
\end{table}

We can see that we reject the null of the first 6 and 12 autocorrelations being zero for both low 10\% and high 10\%, which indicates market predictability for both. Although we reject more strongly for low 10 \%, which indicates what market predictability is more prevalent for lower capitalized stocks than high.

```{r, include=F}
q <- c(2,4,8,16)
res_1 <- vector("list", length(q))
res_2 <- vector("list", length(q))

for (i in 1:length(q)) {
  res_1[[i]] <- c(VDR(lo10, iq = q[i]), list(q = q[i])) 
  res_2[[i]] <- c(VDR(hi10, iq = q[i]), list(q = q[i])) 
}
names(res_1) <- names(res_2) <- q
res_1
res_2
```
\begin{table}[ht]
\centering
\caption{The variance ratio test under RW1. Presented are variance distance, ratio, and p-values for Portfolio returns for low and top 10\%.}
\label{tab:VDRB2}
\begin{tabular}{c|cccc|cccc}
\hline
\multicolumn{1}{c|}{} &
\multicolumn{4}{c|}{Portfolio returns for low 10\%} & \multicolumn{4}{c}{Portfolio returns for top 10\%} \\ \hline
$q$ & VD & p-value & VR & p-value & VD & p-value & VR & p-value \\ \hline
2 & 6.684 & 0.000 & 6.684 & 0.000 & 2.218 & 0.027 & 2.218 & 0.027 \\
4 & 4.656 & 0.000 & 4.656 & 0.000 & 0.690 & 0.490 & 0.690 & 0.490 \\
8 & 1.715 & 0.086 & 1.715 & 0.086 & 0.764 & 0.445 & 0.764 & 0.445 \\
16 & 1.611 & 0.107 & 1.611 & 0.107 & 1.479 & 0.139 & 1.479 & 0.139 \\
\hline
\end{tabular}
\end{table}


We observe that for Lo_10 portfolio returns we reject the null for q 2 and 4 which would suggest that these are not random walks. For q 8 and 16 we cannot reject null and therefore have no evidence to prove that they are not random walks.

For Hi_10 portfolio returns there is some evidence that is contradictory. The theory suggests that the biggest companies should be random walk however our finding when q is 2 is that we can reject the null of random walk. For this reason, we assume that Hi_10 companies are predictable in the very few successive time periods but not longer.

Results from previous studies show that for portfolios of large size companies we should not see any significant autocorrelations, and for portfolios of small-size companies we should see significantly positive autocorrelations. Our results are contradictory, we actually see significant autocorrelations for large size companies. For small-size companies portfolio we do see significant positive autocorrelations, but we also see 1 small spike that is negative, but it perhaps that one can be attributed to chance, as it is not extremely large spike (lag 3).

We can conclude that we see evidence for asset return predictability for both portfolios of large and small companies, but we do not observe what is expected from previous studies.

Next we want to check if these results hold for higher aggregated returns. We will use annualized two-month returns which we create like this.

```{r, echo=T, results='hide'}
onemonth_lo10 <- lo10
onemonth_hi10 <- hi10

twomonth_lo10 <- onemonth_lo10[seq(1, length(onemonth_lo10), by = 2)] +
                 onemonth_lo10[seq(2, length(onemonth_lo10), by = 2)]

twomonth_lo10_ann <- twomonth_lo10/2

twomonth_hi10 <- onemonth_hi10[seq(1, length(onemonth_hi10), by = 2)] +
                 onemonth_hi10[seq(2, length(onemonth_hi10), by = 2)]

twomonth_hi10_ann <- twomonth_hi10/2
```

```{r B1_ACF2, echo=F, warning=F, error=F}
par(mfrow=c(1,2))
p1 <- Acf(twomonth_lo10_ann, lag.max = 12, main = "Portfolio returns for low 10%")
p2 <- Acf(twomonth_hi10_ann, lag.max = 12, main = "Portfolio returns for top 10%.")
par(mfrow=c(1,1))
```
As we can see in the ACF-plots above, there are several significant auto-correlations for the low 10\%, however, for the top 10\% there is only one significant auto-correlation at lag 7. This is an indication that there is likely asset return predictability in the low 10\% but less likely in the top 10\%.

Performing the Ljung-Box test:
```{r, include=F}
lagss <- c(6,12)
results <- matrix(NA, nrow = length(lagss), ncol = 4)
for(i in 1:length(lagss)){
lb1 <- LB(twomonth_lo10_ann,lag=lagss[i],ip=0)
lb2 <- LB(twomonth_hi10_ann,lag=lagss[i],ip=0)
results[i, 1] <- lb1$test
results[i, 2] <- lb1$pval
results[i, 3] <- lb2$test
results[i, 4] <- lb2$pval
}
round(results, 3)
```
\begin{table}[ht]
\centering
\caption{Ljung-Box Test Results for two month aggregated portfolio returns for low and top 10\% with lag 3 and 6.}
\label{tab:LB_test}
\begin{tabular}{lcccc}
\toprule
\multirow{2}{*}{Lag} & \multicolumn{2}{c}{Low 10\%} & \multicolumn{2}{c}{Top 10\%} \\ 
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
 & $Q_{LB}$ & p-value & $Q_{LB}$ & p-value \\ 
\midrule
6  & 17.380 & 0.008 & 7.232  & 0.300 \\ 
12  & 39.492  & 0.000  & 25.595   & 0.012 \\ 
\bottomrule
\end{tabular}
\end{table}
What we see in table \ref{tab:LB_test} that we reject the nulls of the first 6 autocorrelations being zero for the Low 10% but not for the Top 10%. But when we extend to the first 12 autocorrelations, we see that we reject for both on a 5% significance level. This indicates that for two month aggregated returns, we see evidence of asset return predictability for both Low 10% and Top 10%, but stronger evidence for Low 10%.

Looking at the variance ratio test:
```{r, include=F}
q <- c(2,4,8,16)
res_lo <- matrix(NA, nrow=4, ncol=4)
res_hi <- matrix(NA, nrow=4, ncol=4)

for (i in 1:length(q)){
res_1 <- VDR(vr=twomonth_lo10_ann,iq=q[i])
res_2 <- VDR(vr=twomonth_hi10_ann,iq=q[i])
res_lo[i,1] <- res_1$VD
res_lo[i,2] <- res_1$RW1_p_VD
res_lo[i,3] <- res_1$VR
res_lo[i,4] <- res_1$RW1_p_VR
res_hi[i,1] <- res_2$VD
res_hi[i,2] <- res_2$RW1_p_VD
res_hi[i,3] <- res_2$VR
res_hi[i,4] <- res_2$RW1_p_VR
}
cbind(round(res_lo,3),round(res_hi,3))
```
\begin{table}[ht]
\centering
\caption{The variance ratio test under RW1. Presented are variance distance, ratio, and p-values for Portfolio returns for low and top 10\%.}
\label{tab:VDRB22}
\begin{tabular}{c|cccc|cccc}
\hline
\multicolumn{1}{c|}{} &
\multicolumn{4}{c|}{Portfolio returns for low 10\%} & \multicolumn{4}{c}{Portfolio returns for top 10\%} \\ \hline
$q$ & VD & p-value & VR & p-value & VD & p-value & VR & p-value \\ \hline
2  & 0.772 & 0.440 & 0.772 & 0.440 & -0.702 & 0.483 & -0.702 & 0.483 \\
4  & -0.952 & 0.341 & -0.952 & 0.341 & -0.031 & 0.975 & -0.031 & 0.975 \\
8  & -0.370 & 0.712 & -0.370 & 0.712 & 0.899 & 0.369 & 0.899 & 0.369 \\
16 & -0.695 & 0.487 & -0.695 & 0.487 & 0.390 & 0.697 & 0.390 & 0.697 \\
\hline
\end{tabular}
\end{table}
In table \ref{tab:VDRB22} we see the results from the variance ratio test for the two month aggregated portfolio returns. Here we see the results that we cannot reject the null, contradicting the results from the ACF-plots and Ljung-Box test. This makes it more difficult to come to a conclusion, but we believe based on the ACF and Ljung-Box test that there is likely asset return predictability in the low 10\% but not in the top 10\% for the two month aggregated returns.


## 2. Is this relationship stable over time?

Let us split up it in three time periods.


```{r, echo=F,fig.pos = "H",fig.height=4, fig.width=6}
lo10p1 <- portcap_m$Lo_10[1:314] #period 1
lo10p2 <- portcap_m$Lo_10[315:628] #period 2
lo10p3 <- portcap_m$Lo_10[629:942] #period 3

#length(lo10p1)
#length(lo10p2)
#length(lo10p3)

hi10p1 <- portcap_m$Hi_10[1:314] #period 1
hi10p2 <- portcap_m$Hi_10[315:628] #period 2
hi10p3 <- portcap_m$Hi_10[629:942] #period 3

par(mfrow=c(1,3))

Acf(lo10p1, lag.max = 20, main = paste("ACF for lo_10 period 1"), ylim = c(-0.25, 0.25))
Acf(lo10p2, lag.max = 20, main = paste("ACF for lo_10 period 2"), ylim = c(-0.25, 0.25))
Acf(lo10p3, lag.max = 20, main = paste("ACF for lo_10 period 3"), ylim = c(-0.25, 0.25))
par(mfrow=c(1,1))

```


```{r, echo=F,fig.pos = "H",fig.height=4, fig.width=6}
par(mfrow=c(1,3))
Acf(hi10p1, lag.max = 20, main = paste("ACF for hi_10 period 1"), ylim = c(-0.25, 0.25))
Acf(hi10p2, lag.max = 20, main = paste("ACF for hi_10 period 2"), ylim = c(-0.25, 0.25))
Acf(hi10p3, lag.max = 20, main = paste("ACF for hi_10 period 3"), ylim = c(-0.25, 0.25))
par(mfrow=c(1,1))

#LB(lo10p1,lag=12,ip=0)
#LB(hi10p1,lag=12,ip=0)

#LB(lo10p2,lag=12,ip=0)
#LB(hi10p2,lag=12,ip=0)

#LB(lo10p3,lag=12,ip=0)
#LB(hi10p3,lag=12,ip=0)
```
Looking at the ACF plots above, we see significant spikes for the lo 10\% for all three time periods. For the top 10\% we also see significant spikes for all periods, however the results from period two and three are somewhat inconclusive with autocorrelations which are not as significant compared to the lowest 10\%. Based on this, we believe that there is likely asset return predictability for the low 10\% for all periods while we are less confident for the top 10\%.

\begin{table}[ht]
\centering
\caption{Ljung-Box Test Results for Different Portfolios}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Portfolio} & \textbf{Test Statistic} & \textbf{p-value} \\ \hline
Lo10 (Period 1) & 37.070 & 0.000 \\ \hline
Hi10 (Period 1) & 26.537 & 0.009 \\ \hline
Lo10 (Period 2) & 36.781 & 0.000 \\ \hline
Hi10 (Period 2) & 18.119 & 0.112 \\ \hline
Lo10 (Period 3) & 34.388 & 0.001 \\ \hline
Hi10 (Period 3) & 13.472 & 0.336 \\ \hline
\end{tabular}
\label{tab:LB_test_results}
\end{table}

We can see that we reject the null of the first 12 autocorrelations being zero for Low 10% period 1, High 10% period 1, Low 10% period 2 and Low 10% period 3. We can not reject the null of the first 12 autocorrelations being zero for High 10% period 2 and High 10% period 3. What does this tell us? It tells us that for the Low 10% portfolio, we see evidence for asset return predictability in all 3 periods, whereas for High 10% we only see evidence for asset return predictability for period 1, not for period 2 and 3.


## 3. Are there significant cross-autocorrelations between different size portfolios? 

```{r, echo=F}
res <- ccf(lo10, hi10, lag.max = 20)
```


When negative lag, it means that the returns of Lo_10 is compared to the future returns of the Hi_10. When positive lags it means that the Hi_10 is compared to the future returns of the Lo_10. We observe significant lags both for negative and positive lags. Furthermore, the lags are in both directions, both positive and negative cross-autocorrelations and for this reason it is very hard to draw one general conclusion. One thing that is evident is however the significant lag 1, which means that Hi_10 is correlated with short-term future returns of Lo_10, supporting the theory that big companies leads and small companies lags. We will continue by dividing it into subperiods and examining the autocorrelations again. Above is a table of the magnitudes. 
```{r, echo=F}
par(mfrow=c(1,3))
res_1 <- ccf(lo10p1, hi10p1, lag.max = 20)
res_2 <- ccf(lo10p2, hi10p2, lag.max = 20)
res_3 <- ccf(lo10p3, hi10p3, lag.max = 20)
par(mfrow=c(1,1))
```
For period 1, it is evident that there are more significant positive lags than negative, supporting the theory of leading large companies. In the second period we observe no significant negative lags but three significant positive lags which are at lags 1, 3, and 7. Finally, for period three we observe two significant negative lags (8, 12) and four significant positive lags (1, 4, 16, and 18). These findings suggest that lag 1 is always positive and significant which supports the theory of leading large companies. Following is a table of the magnitudes. 

Finally, we conduct a Ljung-Box test to test if the cross autocorrelation are significant. 
```{r, include=F}
LB(res$acf, lag = 12, ip = 0)
LB(res_1$acf, lag = 12, ip = 0)
LB(res_2$acf, lag = 12, ip = 0)
LB(res_3$acf, lag = 12, ip = 0)
```
\begin{table}[ht]
\centering
\caption{Cross-Correlation Function (CCF) Ljung-Box Test Results with lag 12.}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Period} & \textbf{Test Statistic} & \textbf{p-value} \\ \hline
Overall         & 15.029                  & 0.240            \\ \hline
Period 1        & 25.202                  & 0.014            \\ \hline
Period 2        & 12.386                  & 0.415            \\ \hline
Period 3        & 12.216                  & 0.428            \\ \hline
\end{tabular}
\label{tab:CCF_LB_test_results}
\end{table}

We observe that there are no significant test statistics except for the first period. We also found evidence that the first positive lag would almost always be significant so we test only one lag also. 

```{r, include=F}
LB(res$acf, lag = 1, ip = 0)
LB(res_1$acf, lag = 1, ip = 0)
LB(res_2$acf, lag = 1, ip = 0)
LB(res_3$acf, lag = 1, ip = 0)
```
\begin{table}[ht]
\centering
\caption{Ljung-Box Test Results at Lag 1}
\begin{tabular}{lcc}
\hline
\textbf{Series} & \textbf{Test Statistic} & \textbf{p-value} \\
\hline
Full Sample     & 5.306 & 0.021 \\
Period 1     & 5.190 & 0.023 \\
Period 2    & 3.269 & 0.071 \\
Period 3     & 4.241 & 0.039 \\
\hline
\end{tabular}
\label{tab:lb_lag1}
\end{table}

In this case, all periods except for the third are significant at a 5\% level, the third is significant at 10\% level. This concludes and confirms the theory that large companies are leading, at least in short-term. 

## 4. Can you confirm the results of Campbell/Lo/MacKinlay (1997) that high-cap stocks lead small-cap stocks? How stable is this result over time?

Yes, we can confirm the results of Campbell/Lo/Mackinlay (1997) and the theory that high-cap stocks lead small-cap stocks, at least in the short term. The results are stable over time on a 10\% level and on a 5\% level on the whole dataset and in period 1 and 3. 


